#!/usr/bin/env python3
"""
Script unifi√© pour optimisation CSS compl√®te en 4 √©tapes:
1. D√©tection des classes inutilis√©es
2. V√©rification parall√©lis√©e 
3. Suppression des classes confirm√©es inutilis√©es
4. Consolidation des r√®gles CSS dupliqu√©es

Usage: python css_optimizer.py [--step STEP] [--threads N] [--dry-run] [--skip-step STEP]
"""

import re
import os
import shutil
import fnmatch
from pathlib import Path
from typing import Set, List, Dict, Tuple
from collections import OrderedDict
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
import argparse
from datetime import datetime
import json
import sys
import glob

def load_config(config_file='.css-optimizer.json'):
    """Charge la configuration ou utilise des valeurs par d√©faut."""
    default_config = {
        'css_files': ['*.css'],
        'search_directories': ['.'],
        'search_extensions': ['.html', '.js', '.jsx', '.ts', '.tsx', '.vue', '.py'],
        'ignore_patterns': [],
        'exclude_dirs': ['node_modules', '.git', 'dist', 'build', 'venv', '__pycache__'],
        'exclude_files': ['css_optimizer.py', 'css_step*.txt', 'css_optimization_report.txt'],
        'search_mode': 'safe'  # 'safe' = d√©tection permissive, 'strict' = patterns exacts uniquement
    }
    
    if os.path.exists(config_file):
        with open(config_file, 'r') as f:
            user_config = json.load(f)
            default_config.update(user_config)
    
    return default_config

class CSSOptimizer:
    def __init__(self, dry_run=False, threads=8, config_file='.css-optimizer.json', force_mode=None):
        config = load_config(config_file)
        
        self.css_files = self._expand_css_files(config['css_files'])
        self.search_extensions = config['search_extensions']
        self.search_directories = config['search_directories']
        self.ignore_patterns = config['ignore_patterns']
        self.exclude_dirs = config['exclude_dirs']
        self.exclude_files = config.get('exclude_files', ['css_optimizer.py', 'css_step*.txt', 'css_optimization_report.txt'])
        self.search_mode = force_mode or config.get('search_mode', 'safe')
        self.dry_run = dry_run
        self.max_threads = threads
        
        # Afficher le mode de recherche
        if self.search_mode == 'safe':
            print("üõ°Ô∏è  Mode SAFE : D√©tection permissive (√©vite les suppressions accidentelles)")
        else:
            print("‚ö° Mode STRICT : D√©tection exacte (peut manquer certains usages)")
        
        # Statistiques globales
        self.global_stats = {
            'step1_total_classes': 0,
            'step1_unused_classes': 0,
            'step2_confirmed_unused': 0,
            'step2_actually_used': 0,
            'step3_classes_removed': 0,
            'step3_bytes_saved': 0,
            'step4_rules_merged': 0,
            'step4_bytes_saved': 0,
            'total_time': 0
        }
        
        # Donn√©es partag√©es entre √©tapes
        self.unused_classes = []
        self.confirmed_unused = []
        self.css_rules = {}
        
        # Pour la progression parall√®le
        self.progress_lock = threading.Lock()
        self.completed_tasks = 0
        self.total_tasks = 0
    
    # ============= √âTAPE 1: D√âTECTION =============
    def _expand_css_files(self, patterns):
        """Expand glob patterns pour trouver les fichiers CSS."""
        css_files = []
        for pattern in patterns:
            if '*' in pattern:
                css_files.extend(glob.glob(pattern, recursive=True))
            else:
                if os.path.exists(pattern):
                    css_files.append(pattern)
        return css_files
    
    def _should_exclude_file(self, filename: str) -> bool:
        """V√©rifie si un fichier doit √™tre exclu de la recherche."""
        basename = os.path.basename(filename)
        
        for pattern in self.exclude_files:
            if '*' in pattern:
                if fnmatch.fnmatch(basename, pattern):
                    return True
            elif pattern in basename:
                return True
        
        return False

    def step1_detect_unused(self) -> Dict:
        """√âtape 1: D√©tecte les classes CSS potentiellement inutilis√©es."""
        print("\n" + "="*70)
        print("üìã √âTAPE 1: D√âTECTION DES CLASSES INUTILIS√âES")
        print("="*70)
        
        all_classes = set()
        
        # Extraire toutes les classes CSS
        for css_file in self.css_files:
            if os.path.exists(css_file):
                classes = self._extract_css_classes(css_file)
                all_classes.update(classes)
                print(f"üìÅ {css_file}: {len(classes)} classes trouv√©es")
        
        self.global_stats['step1_total_classes'] = len(all_classes)
        print(f"\nüìä Total: {len(all_classes)} classes CSS √† v√©rifier")
        
        # V√©rifier chaque classe
        unused = []
        used = []
        
        for i, class_name in enumerate(sorted(all_classes), 1):
            print(f"üîé [{i}/{len(all_classes)}] V√©rification: .{class_name}", end="")
            
            usage_files = self._quick_search_class(class_name)
            
            if usage_files:
                used.append(class_name)
                print(f" ‚úÖ UTILIS√âE")
            else:
                unused.append(class_name)
                print(f" ‚ùå INUTILIS√âE")
        
        self.unused_classes = unused
        self.global_stats['step1_unused_classes'] = len(unused)
        
        # G√©n√©rer rapport √©tape 1
        self._generate_step1_report(unused, used)
        
        return {
            'total_classes': len(all_classes),
            'unused_classes': unused,
            'used_classes': used
        }
    
    def _extract_css_classes(self, css_file: str) -> Set[str]:
        """Extrait toutes les classes CSS d'un fichier."""
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except FileNotFoundError:
            print(f"‚ùå Fichier CSS non trouv√©: {css_file}")
            return set()
        
        # Enlever les commentaires CSS
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        
        # Ignorer le contenu des @keyframes et @media pour l'extraction
        content_without_at_rules = self._remove_at_rules_for_extraction(content)
        
        # Regex pour trouver les classes CSS
        class_pattern = r'\.([a-zA-Z][\w-]+)(?=\s*[{,\s:[])'
        matches = re.findall(class_pattern, content_without_at_rules)
        
        # Filtrer les classes √† ignorer
        classes = set()
        for match in matches:
            if not any(re.match(pattern, match) for pattern in self.ignore_patterns):
                classes.add(match)
        
        return classes
    
    def _remove_at_rules_for_extraction(self, content: str) -> str:
        """Enl√®ve temporairement les @rules pour l'extraction des classes."""
        # Enlever @keyframes
        content = re.sub(r'@keyframes\s+[\w-]+\s*\{(?:[^{}]*\{[^{}]*\})*[^{}]*\}', '', content, flags=re.MULTILINE | re.DOTALL)
        
        # Enlever @media et autres @rules avec blocs imbriqu√©s
        lines = content.split('\n')
        new_lines = []
        in_at_rule = False
        brace_count = 0
        
        for line in lines:
            if '@' in line and '{' in line:
                in_at_rule = True
                brace_count = line.count('{') - line.count('}')
            elif in_at_rule:
                brace_count += line.count('{') - line.count('}')
                if brace_count <= 0:
                    in_at_rule = False
                    brace_count = 0
            elif not in_at_rule:
                new_lines.append(line)
        
        return '\n'.join(new_lines)
    
    def _quick_search_class(self, class_name: str) -> List[str]:
        """Recherche rapide d'une classe dans le projet."""
        found_files = []
        escaped_name = re.escape(class_name)
        
        # Patterns de base (mode strict)
        patterns_strict = [
            # Patterns HTML
            rf'class\s*=\s*["\'][^"\']*\b{escaped_name}\b[^"\']*["\']',
            # Patterns JS/TS pour utilisation directe
            rf'\.{escaped_name}(?![a-zA-Z0-9_-])',
            rf'querySelector[^(]*\([^)]*\.{escaped_name}(?![a-zA-Z0-9_-])',
            rf'classList\.[^(]+\(["\']?{escaped_name}(?![a-zA-Z0-9_-])',
            rf'className[^=]*=[^"\']*["\'][^"\']*\b{escaped_name}\b',
        ]
        
        # Patterns additionnels pour mode safe
        patterns_safe = [
            # Pattern g√©n√©ral pour TOUTE cha√Æne contenant la classe
            rf'["\'][^"\']*{escaped_name}[^"\']*["\']',
            rf'`[^`]*{escaped_name}[^`]*`',  # Template literals
        ]
        
        # Choisir les patterns selon le mode
        if self.search_mode == 'safe':
            patterns = patterns_strict + patterns_safe
        else:
            patterns = patterns_strict
        
        for directory in self.search_directories:
            if not os.path.exists(directory):
                continue
                
            for root, dirs, files in os.walk(directory):
                dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
                
                for file in files:
                    if self._should_exclude_file(file):
                        continue
                        
                    if any(file.endswith(ext) for ext in self.search_extensions):
                        file_path = os.path.join(root, file)
                        
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                            
                            # Enlever les commentaires pour √©viter les faux positifs
                            if file.endswith('.py'):
                                content = re.sub(r'#.*$', '', content, flags=re.MULTILINE)
                                content = re.sub(r'""".*?"""', '', content, flags=re.DOTALL)
                                content = re.sub(r"'''.*?'''", '', content, flags=re.DOTALL)
                            elif file.endswith(('.js', '.jsx', '.ts', '.tsx')):
                                # Enlever les commentaires JS
                                content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
                                content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
                            
                            for pattern in patterns:
                                if re.search(pattern, content, re.IGNORECASE):
                                    found_files.append(file_path)
                                    break
                        except Exception:
                            pass
        
        return found_files
    
    # ============= √âTAPE 2: V√âRIFICATION PARALL√âLIS√âE =============
    
    def step2_verify_parallel(self) -> Dict:
        """√âtape 2: V√©rification parall√©lis√©e approfondie des classes inutilis√©es."""
        if not self.unused_classes:
            print("\n‚ö†Ô∏è  Aucune classe inutilis√©e √† v√©rifier")
            return {}
        
        print("\n" + "="*70)
        print("üîç √âTAPE 2: V√âRIFICATION PARALL√âLIS√âE")
        print("="*70)
        
        self.total_tasks = len(self.unused_classes)
        self.completed_tasks = 0
        
        print(f"üöÄ V√©rification de {len(self.unused_classes)} classes avec {self.max_threads} threads...")
        print("üìä Progression:")
        
        start_time = time.time()
        
        confirmed_unused = []
        actually_used = []
        suspicious_cases = []
        
        # Traitement parall√®le
        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            future_to_class = {
                executor.submit(self._analyze_single_class, class_name): class_name
                for class_name in self.unused_classes
            }
            
            for future in as_completed(future_to_class):
                class_name = future_to_class[future]
                try:
                    analysis = future.result()
                    
                    if analysis['status'] == 'UNUSED':
                        confirmed_unused.append(class_name)
                    elif analysis['total_occurrences'] == 1:
                        suspicious_cases.append(class_name)
                    else:
                        actually_used.append(class_name)
                        
                except Exception:
                    pass
        
        end_time = time.time()
        print(f"\n‚ö° Analyse termin√©e en {end_time - start_time:.1f}s")
        
        self.confirmed_unused = confirmed_unused
        self.global_stats['step2_confirmed_unused'] = len(confirmed_unused)
        self.global_stats['step2_actually_used'] = len(actually_used)
        
        # G√©n√©rer rapport √©tape 2
        self._generate_step2_report(confirmed_unused, actually_used, suspicious_cases)
        
        return {
            'confirmed_unused': confirmed_unused,
            'actually_used': actually_used,
            'suspicious': suspicious_cases
        }
    
    def _analyze_single_class(self, class_name: str) -> Dict:
        """Analyse approfondie d'une classe."""
        try:
            results = self._deep_search_class(class_name)
            total_occurrences = sum(len(matches) for matches in results.values())
            
            status = "‚úÖ INUTILIS√âE" if total_occurrences == 0 else f"‚ùå UTILIS√âE ({total_occurrences})"
            self._update_progress(class_name, status)
            
            return {
                'class_name': class_name,
                'total_occurrences': total_occurrences,
                'results': results,
                'status': 'UNUSED' if total_occurrences == 0 else 'USED'
            }
        except Exception as e:
            return {
                'class_name': class_name,
                'total_occurrences': 0,
                'results': {},
                'status': 'ERROR'
            }
    
    def _deep_search_class(self, class_name: str) -> Dict[str, List]:
        """Recherche approfondie avec patterns sp√©cifiques."""
        results = {'.html': [], '.js': [], '.py': []}
        
        for directory in self.search_directories:
            if not os.path.exists(directory):
                continue
                
            for root, dirs, files in os.walk(directory):
                dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
                
                for file in files:
                    if self._should_exclude_file(file):
                        continue
                    
                    ext = '.' + file.split('.')[-1] if '.' in file else ''
                    if ext in self.search_extensions:
                        file_path = os.path.join(root, file)
                        matches = self._search_in_file(file_path, class_name, ext)
                        if matches and ext in results:
                            results[ext].extend(matches)
        
        return results
    
    def _search_in_file(self, file_path: str, class_name: str, extension: str) -> List[Tuple]:
        """Recherche dans un fichier avec patterns appropri√©s."""
        if self._should_exclude_file(file_path):
            return []
            
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except Exception:
            return []
        
        # Pour les fichiers Python, enlever les commentaires
        if extension == '.py':
            content = re.sub(r'""".*?"""', '', content, flags=re.DOTALL)
            content = re.sub(r"'''.*?'''", '', content, flags=re.DOTALL)
            lines = content.split('\n')
            lines = [re.sub(r'#.*$', '', line) for line in lines]
        
        # Pour les fichiers JS, enlever les commentaires aussi
        if extension in ['.js', '.jsx', '.ts', '.tsx']:
            # Enlever les commentaires // et /* */
            lines_cleaned = []
            in_block_comment = False
            for line in lines:
                # G√©rer les commentaires de bloc
                if '/*' in line and '*/' in line:
                    line = re.sub(r'/\*.*?\*/', '', line)
                elif '/*' in line:
                    line = line[:line.index('/*')]
                    in_block_comment = True
                elif '*/' in line and in_block_comment:
                    line = line[line.index('*/')+2:]
                    in_block_comment = False
                elif in_block_comment:
                    continue
                    
                # Enlever les commentaires de ligne
                if '//' in line:
                    # Attention aux URL qui contiennent //
                    if not re.search(r'https?://', line):
                        line = re.sub(r'//.*$', '', line)
                
                lines_cleaned.append(line)
            lines = lines_cleaned
        
        escaped_name = re.escape(class_name)
        
        # Patterns adapt√©s par type de fichier et mode
        if extension == '.html':
            patterns = [
                rf'class\s*=\s*["\'][^"\']*\b{escaped_name}\b[^"\']*["\']',
            ]
        elif extension in ['.js', '.jsx', '.ts', '.tsx']:
            patterns_strict = [
                # Patterns pour utilisation directe
                rf'\.{escaped_name}(?![a-zA-Z0-9_-])',
                rf'classList\.(?:add|remove|toggle|contains)\s*\(\s*["\']?{escaped_name}(?![a-zA-Z0-9_-])',
                rf'querySelector[^(]*\([^)]*\.{escaped_name}(?![a-zA-Z0-9_-])',
                rf'className[^=]*=[^"\']*["\'][^"\']*\b{escaped_name}\b',
            ]
            
            patterns_safe = [
                # Patterns additionnels pour cas "tordus" (mode safe uniquement)
                rf'return\s+["\']({escaped_name}|[^"\']*\s{escaped_name}|{escaped_name}\s[^"\']*|[^"\']*\s{escaped_name}\s[^"\']*)["\']',
                rf'(?:const|let|var)\s+\w+\s*=\s*["\'][^"\']*{escaped_name}[^"\']*["\']',
                rf':\s*["\'][^"\']*{escaped_name}[^"\']*["\']',
                rf'\[[^\]]*["\'][^"\']*{escaped_name}[^"\']*["\'][^\]]*\]',
                rf'\?\s*["\'][^"\']*{escaped_name}[^"\']*["\']',
                rf'\([^)]*["\'][^"\']*{escaped_name}[^"\']*["\'][^)]*\)',
                rf'`[^`]*{escaped_name}[^`]*`',
                # Pattern le plus permissif en dernier
                rf'["\'][^"\']*{escaped_name}[^"\']*["\']',
            ]
            
            if self.search_mode == 'safe':
                patterns = patterns_strict + patterns_safe
            else:
                patterns = patterns_strict
                
        elif extension == '.py':
            patterns_strict = [
                rf'class\s*=\s*["\'][^"\']*\b{escaped_name}\b[^"\']*["\']',
                rf'f["\'][^"\']*\b{escaped_name}\b[^"\']*["\']',
            ]
            
            if self.search_mode == 'safe':
                # Ajouter le pattern g√©n√©ral pour Python en mode safe
                patterns = patterns_strict + [rf'["\'][^"\']*{escaped_name}[^"\']*["\']']
            else:
                patterns = patterns_strict
        else:
            patterns = [rf'\.{escaped_name}(?![a-zA-Z0-9_-])']
        
        matches = []
        for line_num, line in enumerate(lines, 1):
            if not line.strip():
                continue
                
            for pattern in patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    clean_line = line.strip()[:100] + '...' if len(line.strip()) > 100 else line.strip()
                    matches.append((file_path, line_num, clean_line))
                    break
        
        return matches
    
    def _update_progress(self, class_name: str, status: str) -> None:
        """Met √† jour la progression thread-safe."""
        with self.progress_lock:
            self.completed_tasks += 1
            progress = (self.completed_tasks / self.total_tasks) * 100
            print(f"\rüîç [{self.completed_tasks:3d}/{self.total_tasks}] ({progress:5.1f}%) .{class_name:<20} - {status}", 
                  end="", flush=True)
    
    # ============= √âTAPE 3: SUPPRESSION =============
    
    def step3_remove_classes(self) -> Dict:
        """√âtape 3: Supprime les classes confirm√©es inutilis√©es des fichiers CSS."""
        if not self.confirmed_unused:
            print("\n‚ö†Ô∏è  Aucune classe √† supprimer")
            return {}
        
        print("\n" + "="*70)
        print("üóëÔ∏è  √âTAPE 3: SUPPRESSION DES CLASSES INUTILIS√âES")
        print("="*70)
        
        print(f"üéØ Classes √† supprimer: {len(self.confirmed_unused)}")
        
        # Cr√©er backup
        if not self.dry_run:
            backup_dir = self._create_backup()
            print(f"üíæ Backup cr√©√©: {backup_dir}")
        
        total_bytes_saved = 0
        classes_set = set(self.confirmed_unused)
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                bytes_saved = self._remove_classes_from_file(css_file, classes_set)
                total_bytes_saved += bytes_saved
        
        self.global_stats['step3_classes_removed'] = len(self.confirmed_unused)
        self.global_stats['step3_bytes_saved'] = total_bytes_saved
        
        print(f"\n‚úÖ Suppression termin√©e: {total_bytes_saved:,} octets √©conomis√©s")
        
        return {
            'classes_removed': len(self.confirmed_unused),
            'bytes_saved': total_bytes_saved
        }
    
    def _remove_classes_from_file(self, css_file: str, classes_to_remove: Set[str]) -> int:
        """Supprime les classes du fichier CSS de mani√®re s√ªre."""
        if not os.path.exists(css_file):
            return 0
        
        print(f"üîß Traitement de {css_file}...")
        
        with open(css_file, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        original_size = len(original_content)
        
        # Parser le CSS en pr√©servant la structure
        modified_content = self._safe_remove_classes(original_content, classes_to_remove)
        
        new_size = len(modified_content)
        bytes_saved = original_size - new_size
        
        if not self.dry_run and modified_content != original_content:
            with open(css_file, 'w', encoding='utf-8') as f:
                f.write(modified_content)
            print(f"  üíæ {bytes_saved:,} octets √©conomis√©s")
        elif self.dry_run:
            print(f"  üîç [DRY-RUN] √âconomiserait {bytes_saved:,} octets")
        
        return bytes_saved
    
    def _safe_remove_classes(self, content: str, classes_to_remove: Set[str]) -> str:
        """Supprime les classes de mani√®re s√ªre en pr√©servant la structure CSS."""
        result_lines = []
        lines = content.split('\n')
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # D√©tecter et pr√©server les @keyframes
            if '@keyframes' in line:
                keyframe_block = [line]
                brace_count = line.count('{') - line.count('}')
                i += 1
                
                while i < len(lines) and brace_count > 0:
                    keyframe_block.append(lines[i])
                    brace_count += lines[i].count('{') - lines[i].count('}')
                    i += 1
                
                result_lines.extend(keyframe_block)
                continue
            
            # D√©tecter les @media, @supports, etc.
            elif line.strip().startswith('@') and '{' in line:
                at_rule_block = [line]
                brace_count = line.count('{') - line.count('}')
                i += 1
                
                at_rule_content = []
                while i < len(lines) and brace_count > 0:
                    at_rule_content.append(lines[i])
                    brace_count += lines[i].count('{') - lines[i].count('}')
                    i += 1
                
                # Traiter le contenu de l'@rule
                at_rule_content_str = '\n'.join(at_rule_content)
                if at_rule_content_str.rstrip().endswith('}'):
                    at_rule_content_str = at_rule_content_str.rstrip()[:-1]
                    modified_at_rule_content = self._process_css_rules(at_rule_content_str, classes_to_remove)
                    
                    if modified_at_rule_content.strip():
                        result_lines.append(line)
                        result_lines.append(modified_at_rule_content)
                        result_lines.append('}')
                else:
                    result_lines.extend([line] + at_rule_content)
                continue
            
            # D√©tecter une r√®gle CSS normale
            elif self._is_css_rule_start(line):
                rule_lines = [line]
                if '{' in line and '}' in line:
                    # R√®gle sur une seule ligne
                    modified_rule = self._process_single_rule(line, classes_to_remove)
                    if modified_rule:
                        result_lines.append(modified_rule)
                    i += 1
                    continue
                elif '{' in line:
                    # R√®gle sur plusieurs lignes
                    i += 1
                    while i < len(lines) and '}' not in lines[i]:
                        rule_lines.append(lines[i])
                        i += 1
                    if i < len(lines):
                        rule_lines.append(lines[i])
                    
                    rule_str = '\n'.join(rule_lines)
                    modified_rule = self._process_single_rule(rule_str, classes_to_remove)
                    if modified_rule:
                        result_lines.append(modified_rule)
                    i += 1
                    continue
            
            # Ligne normale (commentaire, espace, etc.)
            result_lines.append(line)
            i += 1
        
        result = '\n'.join(result_lines)
        
        # Nettoyer les espaces multiples
        result = re.sub(r'\n\s*\n\s*\n+', '\n\n', result)
        
        return result
    
    def _is_css_rule_start(self, line: str) -> bool:
        """D√©tecte si une ligne est le d√©but d'une r√®gle CSS."""
        line = line.strip()
        if not line or line.startswith('//') or line.startswith('/*'):
            return False
        if line.startswith('@'):
            return False
        if re.match(r'^[\.#:\[\w\s,>+~*-]+', line):
            return True
        return False
    
    def _process_single_rule(self, rule: str, classes_to_remove: Set[str]) -> str:
        """Traite une r√®gle CSS unique."""
        match = re.match(r'^([^{]+)\{([^}]*)\}', rule, re.DOTALL)
        if not match:
            return rule
        
        selector = match.group(1).strip()
        properties = match.group(2).strip()
        
        # Traiter les s√©lecteurs multiples
        selectors = [s.strip() for s in selector.split(',')]
        new_selectors = []
        
        for sel in selectors:
            should_remove = False
            for class_name in classes_to_remove:
                class_pattern = rf'\.{re.escape(class_name)}(?![a-zA-Z0-9_-])'
                if re.search(class_pattern, sel):
                    should_remove = True
                    break
            
            if not should_remove:
                new_selectors.append(sel)
        
        if not new_selectors:
            return ''
        
        new_selector = ', '.join(new_selectors)
        
        if '\n' in rule:
            return f"{new_selector} {{\n{properties}\n}}"
        else:
            return f"{new_selector} {{ {properties} }}"
    
    def _process_css_rules(self, content: str, classes_to_remove: Set[str]) -> str:
        """Traite un bloc de r√®gles CSS."""
        lines = content.split('\n')
        result_lines = []
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            if self._is_css_rule_start(line):
                rule_lines = [line]
                if '{' in line and '}' in line:
                    modified_rule = self._process_single_rule(line, classes_to_remove)
                    if modified_rule:
                        result_lines.append(modified_rule)
                    i += 1
                    continue
                elif '{' in line:
                    i += 1
                    while i < len(lines) and '}' not in lines[i]:
                        rule_lines.append(lines[i])
                        i += 1
                    if i < len(lines):
                        rule_lines.append(lines[i])
                    
                    rule_str = '\n'.join(rule_lines)
                    modified_rule = self._process_single_rule(rule_str, classes_to_remove)
                    if modified_rule:
                        result_lines.append(modified_rule)
                    i += 1
                    continue
            
            result_lines.append(line)
            i += 1
        
        return '\n'.join(result_lines)
    
    # ============= √âTAPE 4: CONSOLIDATION =============
    
    def step4_consolidate(self) -> Dict:
        """√âtape 4: Consolide les r√®gles CSS dupliqu√©es."""
        print("\n" + "="*70)
        print("‚ú® √âTAPE 4: CONSOLIDATION DES R√àGLES CSS")
        print("="*70)
        
        total_rules_before = 0
        total_rules_after = 0
        total_bytes_saved = 0
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                result = self._consolidate_file(css_file)
                total_rules_before += result['rules_before']
                total_rules_after += result['rules_after']
                total_bytes_saved += result['bytes_saved']
        
        self.global_stats['step4_rules_merged'] = total_rules_before - total_rules_after
        self.global_stats['step4_bytes_saved'] = total_bytes_saved
        
        if total_rules_before > 0:
            reduction = ((total_rules_before - total_rules_after) / total_rules_before * 100)
            print(f"\nüéâ Consolidation: {reduction:.1f}% de r√©duction")
            print(f"üíæ {total_bytes_saved:,} octets √©conomis√©s")
        
        return {
            'rules_merged': total_rules_before - total_rules_after,
            'bytes_saved': total_bytes_saved
        }
    
    def _consolidate_file(self, css_file: str) -> Dict:
        """Consolide un fichier CSS."""
        if not os.path.exists(css_file):
            return {'rules_before': 0, 'rules_after': 0, 'bytes_saved': 0}
        
        print(f"üìÑ Consolidation de {css_file}...")
        
        with open(css_file, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        original_size = len(original_content)
        
        # Parser les r√®gles CSS en pr√©servant @keyframes et @media
        rules, at_rules = self._parse_css_with_at_rules(original_content)
        rules_before = len(rules)
        print(f"  üìä {rules_before} r√®gles trouv√©es")
        
        # Consolider les r√®gles dupliqu√©es
        consolidated = self._merge_duplicate_rules(rules)
        rules_after = len(consolidated)
        print(f"  ‚ú® {rules_after} r√®gles apr√®s consolidation")
        
        # Reconstruire le CSS
        new_content = self._format_consolidated_with_at_rules(consolidated, at_rules)
        
        new_size = len(new_content)
        bytes_saved = original_size - new_size
        
        if not self.dry_run and new_content != original_content:
            with open(css_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
            print(f"  ‚úÖ {bytes_saved:,} octets √©conomis√©s")
        elif self.dry_run:
            print(f"  üîç [DRY-RUN] √âconomiserait {bytes_saved:,} octets")
        
        return {
            'rules_before': rules_before,
            'rules_after': rules_after,
            'bytes_saved': bytes_saved
        }
    
    def _parse_css_with_at_rules(self, content: str) -> Tuple[List[Dict], List[str]]:
        """Parse le CSS en pr√©servant les @rules."""
        rules = []
        at_rules = []
        
        # Enlever les commentaires
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        
        # Extraire et pr√©server les @keyframes
        keyframes_pattern = r'(@keyframes\s+[\w-]+\s*\{(?:[^{}]*\{[^{}]*\})*[^{}]*\})'
        keyframes = re.findall(keyframes_pattern, content, flags=re.MULTILINE | re.DOTALL)
        at_rules.extend(keyframes)
        
        # Enlever les @keyframes du contenu
        for kf in keyframes:
            content = content.replace(kf, f'/*KEYFRAME_PLACEHOLDER_{len(at_rules)-1}*/')
        
        # Parser les r√®gles normales
        pattern = r'([^{}]+)\s*\{([^{}]+)\}'
        
        for match in re.finditer(pattern, content, re.MULTILINE):
            selector = match.group(1).strip()
            properties_text = match.group(2).strip()
            
            if 'PLACEHOLDER' in selector:
                continue
            
            properties = OrderedDict()
            prop_pattern = r'([^:;]+)\s*:\s*([^;]+);?'
            
            for prop_match in re.finditer(prop_pattern, properties_text):
                prop_name = prop_match.group(1).strip()
                prop_value = prop_match.group(2).strip()
                properties[prop_name] = prop_value
            
            if properties:
                rules.append({
                    'selector': selector,
                    'properties': properties
                })
        
        return rules, at_rules
    
    def _merge_duplicate_rules(self, rules: List[Dict]) -> List[Dict]:
        """Fusionne les r√®gles avec s√©lecteurs identiques."""
        consolidated = OrderedDict()
        
        for rule in rules:
            selector = rule['selector']
            normalized = re.sub(r'\s+', ' ', selector).strip()
            
            if normalized in consolidated:
                consolidated[normalized]['properties'].update(rule['properties'])
            else:
                consolidated[normalized] = {
                    'selector': selector,
                    'properties': OrderedDict(rule['properties'])
                }
        
        return list(consolidated.values())
    
    def _format_consolidated_with_at_rules(self, rules: List[Dict], at_rules: List[str]) -> str:
        """Formate les r√®gles CSS consolid√©es avec les @rules pr√©serv√©es."""
        output = []
        
        # Ajouter les @keyframes en premier
        output.extend(at_rules)
        
        # Ajouter les r√®gles consolid√©es
        for rule in rules:
            selector = rule['selector']
            properties = rule['properties']
            
            if not properties:
                continue
            
            props_lines = [f"    {name}: {value};" for name, value in properties.items()]
            output.append(f"\n{selector} {{")
            output.extend(props_lines)
            output.append("}")
        
        return '\n'.join(output)
    
    # ============= UTILITAIRES =============
    
    def _create_backup(self) -> str:
        """Cr√©e un backup des fichiers CSS."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"css_backup_{timestamp}"
        
        os.makedirs(backup_dir, exist_ok=True)
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                backup_file = os.path.join(backup_dir, os.path.basename(css_file))
                shutil.copy2(css_file, backup_file)
        
        return backup_dir
    
    def _generate_step1_report(self, unused: List[str], used: List[str]) -> None:
        """G√©n√®re le rapport de l'√©tape 1."""
        with open('css_step1_report.txt', 'w', encoding='utf-8') as f:
            f.write("√âTAPE 1: D√âTECTION DES CLASSES INUTILIS√âES\n")
            f.write("="*50 + "\n\n")
            f.write(f"Classes totales: {self.global_stats['step1_total_classes']}\n")
            f.write(f"Classes utilis√©es: {len(used)}\n")
            f.write(f"Classes inutilis√©es: {len(unused)}\n\n")
            
            if unused:
                f.write("CLASSES POTENTIELLEMENT INUTILIS√âES:\n")
                for class_name in sorted(unused):
                    f.write(f".{class_name}\n")
    
    def _generate_step2_report(self, confirmed: List[str], used: List[str], suspicious: List[str]) -> None:
        """G√©n√®re le rapport de l'√©tape 2."""
        with open('css_step2_report.txt', 'w', encoding='utf-8') as f:
            f.write("√âTAPE 2: V√âRIFICATION PARALL√âLIS√âE\n")
            f.write("="*50 + "\n\n")
            f.write(f"Classes confirm√©es inutilis√©es: {len(confirmed)}\n")
            f.write(f"Classes effectivement utilis√©es: {len(used)}\n")
            f.write(f"Cas suspects: {len(suspicious)}\n\n")
            
            if confirmed:
                f.write("CLASSES CONFIRM√âES INUTILIS√âES:\n")
                for class_name in sorted(confirmed):
                    f.write(f".{class_name}\n")
    
    def generate_final_report(self) -> None:
        """G√©n√®re le rapport final complet."""
        print("\n" + "="*70)
        print("üìä RAPPORT FINAL D'OPTIMISATION CSS")
        print("="*70)
        
        report = []
        report.append("RAPPORT FINAL D'OPTIMISATION CSS")
        report.append("="*70)
        report.append(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Mode: {'DRY-RUN' if self.dry_run else 'PRODUCTION'}")
        report.append("")
        
        # Statistiques par √©tape
        report.append("üìã √âTAPE 1 - D√âTECTION:")
        report.append(f"  ‚Ä¢ Classes totales analys√©es: {self.global_stats['step1_total_classes']}")
        report.append(f"  ‚Ä¢ Classes potentiellement inutilis√©es: {self.global_stats['step1_unused_classes']}")
        report.append("")
        
        report.append("üîç √âTAPE 2 - V√âRIFICATION:")
        report.append(f"  ‚Ä¢ Classes confirm√©es inutilis√©es: {self.global_stats['step2_confirmed_unused']}")
        report.append(f"  ‚Ä¢ Classes effectivement utilis√©es: {self.global_stats['step2_actually_used']}")
        report.append("")
        
        report.append("üóëÔ∏è  √âTAPE 3 - SUPPRESSION:")
        report.append(f"  ‚Ä¢ Classes supprim√©es: {self.global_stats['step3_classes_removed']}")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {self.global_stats['step3_bytes_saved']:,}")
        report.append("")
        
        report.append("‚ú® √âTAPE 4 - CONSOLIDATION:")
        report.append(f"  ‚Ä¢ R√®gles fusionn√©es: {self.global_stats['step4_rules_merged']}")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {self.global_stats['step4_bytes_saved']:,}")
        report.append("")
        
        # Total
        total_saved = self.global_stats['step3_bytes_saved'] + self.global_stats['step4_bytes_saved']
        report.append("üíæ TOTAL:")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {total_saved:,} ({total_saved/1024:.1f} KB)")
        
        # Sauvegarder et afficher
        report_text = '\n'.join(report)
        
        with open('css_optimization_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print('\n'.join(report[3:]))  # Skip header for console
        print(f"\nüìÑ Rapport complet sauvegard√©: css_optimization_report.txt")
    
    def debug_class(self, class_name: str):
        """Debug pourquoi une classe n'est pas supprim√©e."""
        print(f"\nüîç DEBUG pour la classe: .{class_name}")
        print("="*50)
        
        # Test 1: Extraction
        print("\n1Ô∏è‚É£ TEST D'EXTRACTION:")
        all_classes = set()
        for css_file in self.css_files:
            if os.path.exists(css_file):
                classes = self._extract_css_classes(css_file)
                if class_name in classes:
                    print(f"  ‚úÖ Trouv√©e dans {css_file}")
                    all_classes.add(class_name)
                else:
                    print(f"  ‚ùå Pas trouv√©e dans {css_file}")
        
        if class_name not in all_classes:
            print(f"  ‚ö†Ô∏è  La classe n'est pas d√©tect√©e dans les fichiers CSS!")
            return
        
        # Test 2: Recherche rapide
        print("\n2Ô∏è‚É£ TEST DE RECHERCHE RAPIDE:")
        usage_files = self._quick_search_class(class_name)
        if usage_files:
            print(f"  ‚ùå Trouv√©e dans {len(usage_files)} fichiers:")
            for f in usage_files[:5]:
                print(f"    - {f}")
        else:
            print(f"  ‚úÖ Aucune utilisation trouv√©e")
        
        # Test 3: Recherche approfondie
        print("\n3Ô∏è‚É£ TEST DE RECHERCHE APPROFONDIE:")
        results = self._deep_search_class(class_name)
        total_occurrences = sum(len(matches) for matches in results.values())
        
        if total_occurrences > 0:
            print(f"  ‚ùå {total_occurrences} occurrences trouv√©es:")
            for ext, matches in results.items():
                if matches:
                    print(f"\n  Dans les fichiers {ext} ({len(matches)} occurrences):")
                    for file_path, line_num, line_content in matches[:3]:
                        print(f"    {file_path}:{line_num}")
                        print(f"      {line_content}")
        else:
            print(f"  ‚úÖ Aucune occurrence trouv√©e")
        
        print("\n" + "="*50)
        if total_occurrences == 0 and not usage_files:
            print("‚úÖ Cette classe devrait √™tre supprim√©e lors de l'optimisation")
        else:
            print("‚ùå Cette classe ne sera PAS supprim√©e car des utilisations ont √©t√© trouv√©es")
    
    def run(self, steps=None, skip_steps=None, debug_class=None):
        """Lance le processus d'optimisation."""
        # Mode debug pour une classe sp√©cifique
        if debug_class:
            self.debug_class(debug_class)
            return
        
        steps = steps or [1, 2, 3, 4]
        skip_steps = skip_steps or []
        
        print("üöÄ OPTIMISEUR CSS UNIFI√â")
        print("="*70)
        print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üîß Mode: {'DRY-RUN' if self.dry_run else 'PRODUCTION'}")
        print(f"üßµ Threads: {self.max_threads}")
        print(f"üìã √âtapes √† ex√©cuter: {[s for s in steps if s not in skip_steps]}")
        
        start_time = time.time()
        
        # Ex√©cuter les √©tapes demand√©es
        if 1 in steps and 1 not in skip_steps:
            self.step1_detect_unused()
        
        if 2 in steps and 2 not in skip_steps:
            self.step2_verify_parallel()
        
        if 3 in steps and 3 not in skip_steps:
            self.step3_remove_classes()
        
        if 4 in steps and 4 not in skip_steps:
            self.step4_consolidate()
        
        self.global_stats['total_time'] = time.time() - start_time
        
        # G√©n√©rer le rapport final
        self.generate_final_report()
        
        print(f"\n‚è±Ô∏è  Temps total: {self.global_stats['total_time']:.1f}s")
        print("‚úÖ Optimisation termin√©e!")

def main():
    parser = argparse.ArgumentParser(
        description='Optimiseur CSS unifi√© en 4 √©tapes',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python css_optimizer.py                     # Ex√©cute toutes les √©tapes
  python css_optimizer.py --step 1            # Ex√©cute seulement l'√©tape 1
  python css_optimizer.py --step 1 2          # Ex√©cute les √©tapes 1 et 2
  python css_optimizer.py --skip-step 2       # Ex√©cute tout sauf l'√©tape 2
  python css_optimizer.py --dry-run           # Mode simulation
  python css_optimizer.py --threads 16        # Utilise 16 threads pour l'√©tape 2
  python css_optimizer.py --mode strict       # Mode strict (patterns exacts uniquement)
  python css_optimizer.py --debug muscle-readiness2  # Debug pourquoi une classe n'est pas supprim√©e
        """
    )
    
    parser.add_argument('--step', nargs='+', type=int, choices=[1, 2, 3, 4],
                       help='√âtapes sp√©cifiques √† ex√©cuter (1=d√©tection, 2=v√©rification, 3=suppression, 4=consolidation)')
    parser.add_argument('--skip-step', nargs='+', type=int, choices=[1, 2, 3, 4],
                       help='√âtapes √† ignorer')
    parser.add_argument('--dry-run', action='store_true',
                       help='Mode simulation sans modification des fichiers')
    parser.add_argument('--threads', type=int, default=8,
                       help='Nombre de threads pour la v√©rification parall√©lis√©e (d√©faut: 8)')
    parser.add_argument('--mode', choices=['safe', 'strict'], 
                       help='Mode de recherche: safe (d√©faut, plus permissif) ou strict (patterns exacts)')
    parser.add_argument('--debug', type=str, metavar='CLASS_NAME',
                       help='Debug pourquoi une classe sp√©cifique n\'est pas supprim√©e')
    
    args = parser.parse_args()
    
    optimizer = CSSOptimizer(
        dry_run=args.dry_run,
        threads=args.threads,
        force_mode=args.mode
    )
    
    try:
        optimizer.run(
            steps=args.step,
            skip_steps=args.skip_step,
            debug_class=args.debug
        )
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Optimisation interrompue")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        raise

if __name__ == "__main__":
    main()