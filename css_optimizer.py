#!/usr/bin/env python3
"""
Script unifi√© pour optimisation CSS compl√®te en 4 √©tapes:
1. D√©tection des classes inutilis√©es
2. V√©rification parall√©lis√©e 
3. Suppression des classes confirm√©es inutilis√©es
4. Consolidation des r√®gles CSS dupliqu√©es

Usage: python css_optimizer.py [--step STEP] [--threads N] [--dry-run] [--skip-step STEP]
"""

import re
import os
import shutil
from pathlib import Path
from typing import Set, List, Dict, Tuple
from collections import OrderedDict
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
import argparse
from datetime import datetime
import json
import signal
import sys

class CSSOptimizer:
    def __init__(self, dry_run=False, threads=8):
        self.css_files = ['frontend/styles.css', 'frontend/muscle-colors.css']
        self.search_extensions = ['.html', '.js', '.py']
        self.search_directories = ['frontend/', 'backend/', '.']
        self.dry_run = dry_run
        self.max_threads = threads
        
        # Patterns √† ignorer
        self.ignore_patterns = [
            r'^muscle-\w+',      # Classes dynamiques muscles
            r'^chart-\w+',       # Classes Chart.js
            r'^animation-\w+',   # Classes animations
            r'^hover\w*',        # Classes hover states
            r'^active\w*',       # Classes active states
            r'^\w+-\d+$',        # Classes avec num√©ros (ex: col-12)
        ]
        
        # Statistiques globales
        self.global_stats = {
            'step1_total_classes': 0,
            'step1_unused_classes': 0,
            'step2_confirmed_unused': 0,
            'step2_actually_used': 0,
            'step3_classes_removed': 0,
            'step3_bytes_saved': 0,
            'step4_rules_merged': 0,
            'step4_bytes_saved': 0,
            'total_time': 0
        }
        
        # Donn√©es partag√©es entre √©tapes
        self.unused_classes = []
        self.confirmed_unused = []
        self.css_rules = {}
        
        # Pour la progression parall√®le
        self.progress_lock = threading.Lock()
        self.completed_tasks = 0
        self.total_tasks = 0
        
        # Patterns de recherche JavaScript
        self.js_patterns = [
            r'classList\.(?:add|remove|toggle|contains)\s*\(\s*["\']([^"\']*{classname}[^"\']*)["\']',
            r'className\s*[=+]\s*["\'][^"\']*\b{classname}\b[^"\']*["\']',
            r'querySelector(?:All)?\s*\(\s*["\'][^"\']*\.{classname}(?:[^"\']*)?["\']',
            r'getElementById\s*\([^)]*\)\.classList\.(?:add|remove|toggle)\([^)]*["\']([^"\']*{classname}[^"\']*)["\']',
            r'document\.getElementsByClassName\s*\(\s*["\']([^"\']*{classname}[^"\']*)["\']',
            r'\.{classname}\b',
            r'["\']([^"\']*\s{classname}\s[^"\']*)["\']',
            r'["\']([^"\']*{classname}[^"\']*)["\']',
        ]
        
        # Patterns HTML
        self.html_patterns = [
            r'class\s*=\s*["\'][^"\']*\b{classname}\b[^"\']*["\']',
            r'class\s*=\s*["\']([^"\']*{classname}[^"\']*)["\']',
        ]
        
        # Patterns Python
        self.python_patterns = [
            r'class\s*=\s*["\'][^"\']*\b{classname}\b[^"\']*["\']',
            r'f["\'][^"\']*\b{classname}\b[^"\']*["\']',
            r'["\']([^"\']*{classname}[^"\']*)["\']',
        ]
    
    # ============= √âTAPE 1: D√âTECTION =============
    
    def step1_detect_unused(self) -> Dict:
        """√âtape 1: D√©tecte les classes CSS potentiellement inutilis√©es."""
        print("\n" + "="*70)
        print("üìã √âTAPE 1: D√âTECTION DES CLASSES INUTILIS√âES")
        print("="*70)
        
        all_classes = set()
        
        # Extraire toutes les classes CSS
        for css_file in self.css_files:
            if os.path.exists(css_file):
                classes = self._extract_css_classes(css_file)
                all_classes.update(classes)
                print(f"üìÅ {css_file}: {len(classes)} classes trouv√©es")
        
        self.global_stats['step1_total_classes'] = len(all_classes)
        print(f"\nüìä Total: {len(all_classes)} classes CSS √† v√©rifier")
        
        # V√©rifier chaque classe (recherche basique)
        unused = []
        used = []
        
        for i, class_name in enumerate(sorted(all_classes), 1):
            print(f"üîé [{i}/{len(all_classes)}] V√©rification: .{class_name}", end="")
            
            usage_files = self._quick_search_class(class_name)
            
            if usage_files:
                used.append(class_name)
                print(f" ‚úÖ UTILIS√âE")
            else:
                unused.append(class_name)
                print(f" ‚ùå INUTILIS√âE")
        
        self.unused_classes = unused
        self.global_stats['step1_unused_classes'] = len(unused)
        
        # G√©n√©rer rapport √©tape 1
        self._generate_step1_report(unused, used)
        
        return {
            'total_classes': len(all_classes),
            'unused_classes': unused,
            'used_classes': used
        }
    
    def _extract_css_classes(self, css_file: str) -> Set[str]:
        """Extrait toutes les classes CSS d'un fichier."""
        try:
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except FileNotFoundError:
            print(f"‚ùå Fichier CSS non trouv√©: {css_file}")
            return set()
        
        # Regex pour trouver les classes CSS
        class_pattern = r'\.([a-zA-Z][\w-]+)(?=\s*[{,\s])'
        matches = re.findall(class_pattern, content)
        
        # Filtrer les classes √† ignorer
        classes = set()
        for match in matches:
            if not any(re.match(pattern, match) for pattern in self.ignore_patterns):
                classes.add(match)
        
        return classes
    
    def _quick_search_class(self, class_name: str) -> List[str]:
        """Recherche rapide d'une classe dans le projet."""
        found_files = []
        patterns = [rf'\b{re.escape(class_name)}\b']
        
        for directory in self.search_directories:
            if not os.path.exists(directory):
                continue
                
            for root, dirs, files in os.walk(directory):
                dirs[:] = [d for d in dirs if d not in ['__pycache__', 'node_modules', '.git', 'venv']]
                
                for file in files:
                    if any(file.endswith(ext) for ext in self.search_extensions):
                        file_path = os.path.join(root, file)
                        
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                            
                            for pattern in patterns:
                                if re.search(pattern, content, re.IGNORECASE):
                                    found_files.append(file_path)
                                    break
                        except Exception:
                            pass
        
        return found_files
    
    # ============= √âTAPE 2: V√âRIFICATION PARALL√âLIS√âE =============
    
    def step2_verify_parallel(self) -> Dict:
        """√âtape 2: V√©rification parall√©lis√©e approfondie des classes inutilis√©es."""
        if not self.unused_classes:
            print("\n‚ö†Ô∏è  Aucune classe inutilis√©e √† v√©rifier")
            return {}
        
        print("\n" + "="*70)
        print("üîç √âTAPE 2: V√âRIFICATION PARALL√âLIS√âE")
        print("="*70)
        
        self.total_tasks = len(self.unused_classes)
        self.completed_tasks = 0
        
        print(f"üöÄ V√©rification de {len(self.unused_classes)} classes avec {self.max_threads} threads...")
        print("üìä Progression:")
        
        start_time = time.time()
        
        confirmed_unused = []
        actually_used = []
        suspicious_cases = []
        
        # Traitement parall√®le
        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            future_to_class = {
                executor.submit(self._analyze_single_class, class_name): class_name
                for class_name in self.unused_classes
            }
            
            for future in as_completed(future_to_class):
                class_name = future_to_class[future]
                try:
                    analysis = future.result()
                    
                    if analysis['status'] == 'UNUSED':
                        confirmed_unused.append(class_name)
                    elif analysis['total_occurrences'] == 1:
                        suspicious_cases.append(class_name)
                    else:
                        actually_used.append(class_name)
                        
                except Exception:
                    pass
        
        end_time = time.time()
        print(f"\n‚ö° Analyse termin√©e en {end_time - start_time:.1f}s")
        
        self.confirmed_unused = confirmed_unused
        self.global_stats['step2_confirmed_unused'] = len(confirmed_unused)
        self.global_stats['step2_actually_used'] = len(actually_used)
        
        # G√©n√©rer rapport √©tape 2
        self._generate_step2_report(confirmed_unused, actually_used, suspicious_cases)
        
        return {
            'confirmed_unused': confirmed_unused,
            'actually_used': actually_used,
            'suspicious': suspicious_cases
        }
    
    def _analyze_single_class(self, class_name: str) -> Dict:
        """Analyse approfondie d'une classe."""
        try:
            results = self._deep_search_class(class_name)
            total_occurrences = sum(len(matches) for matches in results.values())
            
            status = "‚úÖ INUTILIS√âE" if total_occurrences == 0 else f"‚ùå UTILIS√âE ({total_occurrences})"
            self._update_progress(class_name, status)
            
            return {
                'class_name': class_name,
                'total_occurrences': total_occurrences,
                'results': results,
                'status': 'UNUSED' if total_occurrences == 0 else 'USED'
            }
        except Exception as e:
            return {
                'class_name': class_name,
                'total_occurrences': 0,
                'results': {},
                'status': 'ERROR'
            }
    
    def _deep_search_class(self, class_name: str) -> Dict[str, List]:
        """Recherche approfondie avec patterns sp√©cifiques."""
        results = {'.html': [], '.js': [], '.py': []}
        
        for directory in self.search_directories:
            if not os.path.exists(directory):
                continue
                
            for root, dirs, files in os.walk(directory):
                dirs[:] = [d for d in dirs if d not in ['__pycache__', 'node_modules', '.git', 'venv']]
                
                for file in files:
                    ext = '.' + file.split('.')[-1] if '.' in file else ''
                    if ext in self.search_extensions:
                        file_path = os.path.join(root, file)
                        matches = self._search_in_file(file_path, class_name, ext)
                        if matches and ext in results:
                            results[ext].extend(matches)
        
        return results
    
    def _search_in_file(self, file_path: str, class_name: str, extension: str) -> List[Tuple]:
        """Recherche dans un fichier avec patterns appropri√©s."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
        except Exception:
            return []
        
        # Choisir les patterns selon l'extension
        if extension == '.html':
            patterns = self.html_patterns
        elif extension == '.js':
            patterns = self.js_patterns
        elif extension == '.py':
            patterns = self.python_patterns
        else:
            patterns = [r'\b{classname}\b']
        
        matches = []
        for line_num, line in enumerate(lines, 1):
            for pattern in patterns:
                formatted_pattern = pattern.format(classname=re.escape(class_name))
                
                if re.search(formatted_pattern, line, re.IGNORECASE):
                    clean_line = line.strip()[:100] + '...' if len(line.strip()) > 100 else line.strip()
                    matches.append((file_path, line_num, clean_line))
                    break
        
        return matches
    
    def _update_progress(self, class_name: str, status: str) -> None:
        """Met √† jour la progression thread-safe."""
        with self.progress_lock:
            self.completed_tasks += 1
            progress = (self.completed_tasks / self.total_tasks) * 100
            print(f"\rüîç [{self.completed_tasks:3d}/{self.total_tasks}] ({progress:5.1f}%) .{class_name:<20} - {status}", 
                  end="", flush=True)
    
    # ============= √âTAPE 3: SUPPRESSION =============
    
    def step3_remove_classes(self) -> Dict:
        """√âtape 3: Supprime les classes confirm√©es inutilis√©es des fichiers CSS."""
        if not self.confirmed_unused:
            print("\n‚ö†Ô∏è  Aucune classe √† supprimer")
            return {}
        
        print("\n" + "="*70)
        print("üóëÔ∏è  √âTAPE 3: SUPPRESSION DES CLASSES INUTILIS√âES")
        print("="*70)
        
        print(f"üéØ Classes √† supprimer: {len(self.confirmed_unused)}")
        
        # Cr√©er backup
        if not self.dry_run:
            backup_dir = self._create_backup()
            print(f"üíæ Backup cr√©√©: {backup_dir}")
        
        total_bytes_saved = 0
        classes_set = set(self.confirmed_unused)
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                bytes_saved = self._remove_classes_from_file(css_file, classes_set)
                total_bytes_saved += bytes_saved
        
        self.global_stats['step3_classes_removed'] = len(self.confirmed_unused)
        self.global_stats['step3_bytes_saved'] = total_bytes_saved
        
        print(f"\n‚úÖ Suppression termin√©e: {total_bytes_saved:,} octets √©conomis√©s")
        
        return {
            'classes_removed': len(self.confirmed_unused),
            'bytes_saved': total_bytes_saved
        }
    
    def _remove_classes_from_file(self, css_file: str, classes_to_remove: Set[str]) -> int:
        """Supprime les classes du fichier CSS."""
        if not os.path.exists(css_file):
            return 0
        
        print(f"üîß Traitement de {css_file}...")
        
        with open(css_file, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        original_size = len(original_content)
        modified_content = original_content
        
        # Supprimer chaque classe
        for class_name in classes_to_remove:
            # Pattern pour supprimer les r√®gles compl√®tes
            rule_pattern = rf'\.{re.escape(class_name)}[^{{]*\{{[^}}]*\}}'
            modified_content = re.sub(rule_pattern, '', modified_content, flags=re.MULTILINE)
            
            # Pattern pour supprimer des s√©lecteurs multiples
            selector_pattern = rf'\.{re.escape(class_name)}(?=[\s,:.#\[])'
            modified_content = re.sub(selector_pattern, '', modified_content)
        
        # Nettoyer les lignes vides multiples
        modified_content = re.sub(r'\n\s*\n\s*\n', '\n\n', modified_content)
        
        new_size = len(modified_content)
        bytes_saved = original_size - new_size
        
        if not self.dry_run and modified_content != original_content:
            with open(css_file, 'w', encoding='utf-8') as f:
                f.write(modified_content)
            print(f"  üíæ {bytes_saved:,} octets √©conomis√©s")
        elif self.dry_run:
            print(f"  üîç [DRY-RUN] √âconomiserait {bytes_saved:,} octets")
        
        return bytes_saved
    
    # ============= √âTAPE 4: CONSOLIDATION =============
    
    def step4_consolidate(self) -> Dict:
        """√âtape 4: Consolide les r√®gles CSS dupliqu√©es."""
        print("\n" + "="*70)
        print("‚ú® √âTAPE 4: CONSOLIDATION DES R√àGLES CSS")
        print("="*70)
        
        total_rules_before = 0
        total_rules_after = 0
        total_bytes_saved = 0
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                result = self._consolidate_file(css_file)
                total_rules_before += result['rules_before']
                total_rules_after += result['rules_after']
                total_bytes_saved += result['bytes_saved']
        
        self.global_stats['step4_rules_merged'] = total_rules_before - total_rules_after
        self.global_stats['step4_bytes_saved'] = total_bytes_saved
        
        if total_rules_before > 0:
            reduction = ((total_rules_before - total_rules_after) / total_rules_before * 100)
            print(f"\nüéâ Consolidation: {reduction:.1f}% de r√©duction")
            print(f"üíæ {total_bytes_saved:,} octets √©conomis√©s")
        
        return {
            'rules_merged': total_rules_before - total_rules_after,
            'bytes_saved': total_bytes_saved
        }
    
    def _consolidate_file(self, css_file: str) -> Dict:
        """Consolide un fichier CSS."""
        if not os.path.exists(css_file):
            return {'rules_before': 0, 'rules_after': 0, 'bytes_saved': 0}
        
        print(f"üìÑ Consolidation de {css_file}...")
        
        with open(css_file, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        original_size = len(original_content)
        
        # Parser les r√®gles CSS
        rules = self._parse_css_rules(original_content)
        rules_before = len(rules)
        print(f"  üìä {rules_before} r√®gles trouv√©es")
        
        # Consolider les r√®gles dupliqu√©es
        consolidated = self._merge_duplicate_rules(rules)
        rules_after = len(consolidated)
        print(f"  ‚ú® {rules_after} r√®gles apr√®s consolidation")
        
        # Reconstruire le CSS
        new_content = self._format_consolidated_css(consolidated)
        
        new_size = len(new_content)
        bytes_saved = original_size - new_size
        
        if not self.dry_run and new_content != original_content:
            with open(css_file, 'w', encoding='utf-8') as f:
                f.write(new_content)
            print(f"  ‚úÖ {bytes_saved:,} octets √©conomis√©s")
        elif self.dry_run:
            print(f"  üîç [DRY-RUN] √âconomiserait {bytes_saved:,} octets")
        
        return {
            'rules_before': rules_before,
            'rules_after': rules_after,
            'bytes_saved': bytes_saved
        }
    
    def _parse_css_rules(self, content: str) -> List[Dict]:
        """Parse le CSS en r√®gles structur√©es."""
        rules = []
        
        # Pattern simple pour capturer s√©lecteur { propri√©t√©s }
        pattern = r'([^{}]+)\s*\{([^{}]+)\}'
        
        for match in re.finditer(pattern, content, re.MULTILINE):
            selector = match.group(1).strip()
            properties_text = match.group(2).strip()
            
            # Parser les propri√©t√©s
            properties = OrderedDict()
            prop_pattern = r'([^:;]+)\s*:\s*([^;]+);?'
            
            for prop_match in re.finditer(prop_pattern, properties_text):
                prop_name = prop_match.group(1).strip()
                prop_value = prop_match.group(2).strip()
                properties[prop_name] = prop_value
            
            if properties:
                rules.append({
                    'selector': selector,
                    'properties': properties
                })
        
        return rules
    
    def _merge_duplicate_rules(self, rules: List[Dict]) -> List[Dict]:
        """Fusionne les r√®gles avec s√©lecteurs identiques."""
        consolidated = OrderedDict()
        
        for rule in rules:
            selector = rule['selector']
            
            # Normaliser le s√©lecteur
            normalized = re.sub(r'\s+', ' ', selector).strip()
            
            if normalized in consolidated:
                # Fusionner les propri√©t√©s (derni√®re valeur gagne)
                consolidated[normalized]['properties'].update(rule['properties'])
            else:
                consolidated[normalized] = {
                    'selector': selector,
                    'properties': OrderedDict(rule['properties'])
                }
        
        return list(consolidated.values())
    
    def _format_consolidated_css(self, rules: List[Dict]) -> str:
        """Formate les r√®gles CSS consolid√©es."""
        output = []
        
        for rule in rules:
            selector = rule['selector']
            properties = rule['properties']
            
            if not properties:
                continue
            
            # Format compact pour une propri√©t√©, multi-ligne pour plusieurs
            if len(properties) == 1:
                prop_name, prop_value = list(properties.items())[0]
                output.append(f"{selector} {{ {prop_name}: {prop_value}; }}")
            else:
                props_lines = [f"    {name}: {value};" for name, value in properties.items()]
                output.append(f"{selector} {{")
                output.extend(props_lines)
                output.append("}")
        
        return '\n\n'.join(output) if len(properties) == 1 else '\n'.join(output)
    
    # ============= UTILITAIRES =============
    
    def _create_backup(self) -> str:
        """Cr√©e un backup des fichiers CSS."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"css_backup_{timestamp}"
        
        os.makedirs(backup_dir, exist_ok=True)
        
        for css_file in self.css_files:
            if os.path.exists(css_file):
                backup_file = os.path.join(backup_dir, os.path.basename(css_file))
                shutil.copy2(css_file, backup_file)
        
        return backup_dir
    
    def _generate_step1_report(self, unused: List[str], used: List[str]) -> None:
        """G√©n√®re le rapport de l'√©tape 1."""
        with open('css_step1_report.txt', 'w', encoding='utf-8') as f:
            f.write("√âTAPE 1: D√âTECTION DES CLASSES INUTILIS√âES\n")
            f.write("="*50 + "\n\n")
            f.write(f"Classes totales: {self.global_stats['step1_total_classes']}\n")
            f.write(f"Classes utilis√©es: {len(used)}\n")
            f.write(f"Classes inutilis√©es: {len(unused)}\n\n")
            
            if unused:
                f.write("CLASSES POTENTIELLEMENT INUTILIS√âES:\n")
                for class_name in sorted(unused):
                    f.write(f".{class_name}\n")
    
    def _generate_step2_report(self, confirmed: List[str], used: List[str], suspicious: List[str]) -> None:
        """G√©n√®re le rapport de l'√©tape 2."""
        with open('css_step2_report.txt', 'w', encoding='utf-8') as f:
            f.write("√âTAPE 2: V√âRIFICATION PARALL√âLIS√âE\n")
            f.write("="*50 + "\n\n")
            f.write(f"Classes confirm√©es inutilis√©es: {len(confirmed)}\n")
            f.write(f"Classes effectivement utilis√©es: {len(used)}\n")
            f.write(f"Cas suspects: {len(suspicious)}\n\n")
            
            if confirmed:
                f.write("CLASSES CONFIRM√âES INUTILIS√âES:\n")
                for class_name in sorted(confirmed):
                    f.write(f".{class_name}\n")
    
    def generate_final_report(self) -> None:
        """G√©n√®re le rapport final complet."""
        print("\n" + "="*70)
        print("üìä RAPPORT FINAL D'OPTIMISATION CSS")
        print("="*70)
        
        report = []
        report.append("RAPPORT FINAL D'OPTIMISATION CSS")
        report.append("="*70)
        report.append(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Mode: {'DRY-RUN' if self.dry_run else 'PRODUCTION'}")
        report.append("")
        
        # Statistiques par √©tape
        report.append("üìã √âTAPE 1 - D√âTECTION:")
        report.append(f"  ‚Ä¢ Classes totales analys√©es: {self.global_stats['step1_total_classes']}")
        report.append(f"  ‚Ä¢ Classes potentiellement inutilis√©es: {self.global_stats['step1_unused_classes']}")
        report.append("")
        
        report.append("üîç √âTAPE 2 - V√âRIFICATION:")
        report.append(f"  ‚Ä¢ Classes confirm√©es inutilis√©es: {self.global_stats['step2_confirmed_unused']}")
        report.append(f"  ‚Ä¢ Classes effectivement utilis√©es: {self.global_stats['step2_actually_used']}")
        report.append("")
        
        report.append("üóëÔ∏è  √âTAPE 3 - SUPPRESSION:")
        report.append(f"  ‚Ä¢ Classes supprim√©es: {self.global_stats['step3_classes_removed']}")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {self.global_stats['step3_bytes_saved']:,}")
        report.append("")
        
        report.append("‚ú® √âTAPE 4 - CONSOLIDATION:")
        report.append(f"  ‚Ä¢ R√®gles fusionn√©es: {self.global_stats['step4_rules_merged']}")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {self.global_stats['step4_bytes_saved']:,}")
        report.append("")
        
        # Total
        total_saved = self.global_stats['step3_bytes_saved'] + self.global_stats['step4_bytes_saved']
        report.append("üíæ TOTAL:")
        report.append(f"  ‚Ä¢ Octets √©conomis√©s: {total_saved:,} ({total_saved/1024:.1f} KB)")
        
        # Sauvegarder et afficher
        report_text = '\n'.join(report)
        
        with open('css_optimization_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print('\n'.join(report[3:]))  # Skip header for console
        print(f"\nüìÑ Rapport complet sauvegard√©: css_optimization_report.txt")
    
    def run(self, steps=None, skip_steps=None):
        """Lance le processus d'optimisation."""
        steps = steps or [1, 2, 3, 4]
        skip_steps = skip_steps or []
        
        print("üöÄ OPTIMISEUR CSS UNIFI√â")
        print("="*70)
        print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üîß Mode: {'DRY-RUN' if self.dry_run else 'PRODUCTION'}")
        print(f"üßµ Threads: {self.max_threads}")
        print(f"üìã √âtapes √† ex√©cuter: {[s for s in steps if s not in skip_steps]}")
        
        start_time = time.time()
        
        # Ex√©cuter les √©tapes demand√©es
        if 1 in steps and 1 not in skip_steps:
            self.step1_detect_unused()
        
        if 2 in steps and 2 not in skip_steps:
            self.step2_verify_parallel()
        
        if 3 in steps and 3 not in skip_steps:
            self.step3_remove_classes()
        
        if 4 in steps and 4 not in skip_steps:
            self.step4_consolidate()
        
        self.global_stats['total_time'] = time.time() - start_time
        
        # G√©n√©rer le rapport final
        self.generate_final_report()
        
        print(f"\n‚è±Ô∏è  Temps total: {self.global_stats['total_time']:.1f}s")
        print("‚úÖ Optimisation termin√©e!")

def main():
    parser = argparse.ArgumentParser(
        description='Optimiseur CSS unifi√© en 4 √©tapes',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python css_optimizer.py                     # Ex√©cute toutes les √©tapes
  python css_optimizer.py --step 1            # Ex√©cute seulement l'√©tape 1
  python css_optimizer.py --step 1 2          # Ex√©cute les √©tapes 1 et 2
  python css_optimizer.py --skip-step 2       # Ex√©cute tout sauf l'√©tape 2
  python css_optimizer.py --dry-run           # Mode simulation
  python css_optimizer.py --threads 16        # Utilise 16 threads pour l'√©tape 2
        """
    )
    
    parser.add_argument('--step', nargs='+', type=int, choices=[1, 2, 3, 4],
                       help='√âtapes sp√©cifiques √† ex√©cuter (1=d√©tection, 2=v√©rification, 3=suppression, 4=consolidation)')
    parser.add_argument('--skip-step', nargs='+', type=int, choices=[1, 2, 3, 4],
                       help='√âtapes √† ignorer')
    parser.add_argument('--dry-run', action='store_true',
                       help='Mode simulation sans modification des fichiers')
    parser.add_argument('--threads', type=int, default=8,
                       help='Nombre de threads pour la v√©rification parall√©lis√©e (d√©faut: 8)')
    
    args = parser.parse_args()
    
    optimizer = CSSOptimizer(
        dry_run=args.dry_run,
        threads=args.threads
    )
    
    try:
        optimizer.run(
            steps=args.step,
            skip_steps=args.skip_step
        )
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Optimisation interrompue")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        raise

if __name__ == "__main__":
    main()