/**
 * üé§ MODULE DE RECONNAISSANCE VOCALE
 * ================================
 * 
 * G√®re le comptage vocal des r√©p√©titions pendant l'exercice.
 * Supporte le comptage naturel ("1, 2, 3...") et par mot-cl√© ("top").
 * 
 * @version 1.0.0
 * @author Assistant
 */

// ===== VARIABLES GLOBALES =====

/**
 * Instance de reconnaissance vocale du navigateur
 * @type {SpeechRecognition|null}
 */
let recognition = null;

/**
 * √âtat de la reconnaissance vocale
 * @type {boolean}
 */
let voiceRecognitionActive = false;

/**
 * Donn√©es de comptage vocal de la session courante
 */
let voiceData = {
    count: 0,
    timestamps: [],
    gaps: [],
    lastNumber: 0,
    lastDetected: 0,        // NOUVEAU - dernier nombre explicitement d√©tect√©
    startTime: null,
    confidence: 1.0,
    suspiciousJumps: 0,     // NOUVEAU - compteur de sauts suspects (+3)
    repetitions: 0,         // NOUVEAU - compteur de r√©p√©titions du m√™me nombre
    needsValidation: false  // NOUVEAU - flag pour forcer validation UI
};


const FRENCH_NUMBERS = new Map([
    // Existant 1-20 (conserver)
    ['un', 1], ['1', 1],
    ['deux', 2], ['2', 2], 
    ['trois', 3], ['3', 3],
    ['quatre', 4], ['4', 4],
    ['cinq', 5], ['5', 5],
    ['six', 6], ['6', 6],
    ['sept', 7], ['7', 7],
    ['huit', 8], ['8', 8],
    ['neuf', 9], ['9', 9],
    ['dix', 10], ['10', 10],
    ['onze', 11], ['11', 11],
    ['douze', 12], ['12', 12],
    ['treize', 13], ['13', 13],
    ['quatorze', 14], ['14', 14],
    ['quinze', 15], ['15', 15],
    ['seize', 16], ['16', 16],
    ['dix-sept', 17], ['17', 17],
    ['dix-huit', 18], ['18', 18],
    ['dix-neuf', 19], ['19', 19],
    ['vingt', 20], ['20', 20],
    ['vingt-et-un', 21], ['21', 21],
    ['vingt-deux', 22], ['22', 22],
    ['vingt-trois', 23], ['23', 23],
    ['vingt-quatre', 24], ['24', 24],
    ['vingt-cinq', 25], ['25', 25],
    ['vingt-six', 26], ['26', 26],
    ['vingt-sept', 27], ['27', 27],
    ['vingt-huit', 28], ['28', 28],
    ['vingt-neuf', 29], ['29', 29],
    ['trente', 30], ['30', 30],
    ['trente-et-un', 31], ['31', 31],
    ['trente-deux', 32], ['32', 32],
    ['trente-trois', 33], ['33', 33],
    ['trente-quatre', 34], ['34', 34],
    ['trente-cinq', 35], ['35', 35],
    ['trente-six', 36], ['36', 36],
    ['trente-sept', 37], ['37', 37],
    ['trente-huit', 38], ['38', 38],
    ['trente-neuf', 39], ['39', 39],
    ['quarante', 40], ['40', 40],
    ['quarante-et-un', 41], ['41', 41],
    ['quarante-deux', 42], ['42', 42],
    ['quarante-trois', 43], ['43', 43],
    ['quarante-quatre', 44], ['44', 44],
    ['quarante-cinq', 45], ['45', 45],
    ['quarante-six', 46], ['46', 46],
    ['quarante-sept', 47], ['47', 47],
    ['quarante-huit', 48], ['48', 48],
    ['quarante-neuf', 49], ['49', 49],
    ['cinquante', 50], ['50', 50]
]);
// Index invers√© pour recherche rapide
const NUMBERS_TO_TEXT = new Map();
for (let [text, num] of FRENCH_NUMBERS) {
    if (!NUMBERS_TO_TEXT.has(num)) {
        NUMBERS_TO_TEXT.set(num, []);
    }
    NUMBERS_TO_TEXT.get(num).push(text);
}

const QUICK_PATTERNS = new Set(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']);

// Niveaux de confiance simplifi√©s
const CONFIDENCE_LEVELS = {
    HIGH: 0.8,    // Auto-validation 1.5s
    MEDIUM: 0.5   // Quick validation 4s
    // LOW: < 0.5  // Manuel requis
};

// NOUVEAU - Mode preview pour tests (D√âCLARER EN PREMIER)
const DEBUG_MODE = false; // Passer √† true pour tester l'interface

// NOUVEAU - Feature toggles avec r√©f√©rence correcte
const VOICE_FEATURES = {
    confidence_system: true,
    validation_ui: true,        // ‚Üê Forcer √† true (production)
    voice_correction: true,
    auto_validation: true,
    ml_enrichment: true,
    passive_mode: true
};

// NOUVEAU - Variables d'√©tat pour la validation
let voiceState = 'LISTENING'; // 'LISTENING' | 'VALIDATING' | 'CONFIRMED'
let validationTimer = null;
// NOUVEAU - Variables pour correction vocale
let correctionMode = false;
let correctionTimer = null;
let passiveListening = false;

// NOUVEAU - Patterns de correction vocale
const CORRECTION_PATTERNS = [
    /correction\s+(\d+)/,           // "correction 15"
    /corriger\s+(\d+)/,             // "corriger 15"  
    /rectifier\s+(\d+)/,            // "rectifier 15"
    /correction\s+(un|deux|trois|quatre|cinq|six|sept|huit|neuf|dix|onze|douze|treize|quatorze|quinze|seize|dix-sept|dix-huit|dix-neuf|vingt|vingt-et-un|vingt-deux|vingt-trois|vingt-quatre|vingt-cinq|vingt-six|vingt-sept|vingt-huit|vingt-neuf|trente|trente-et-un|trente-deux|trente-trois|trente-quatre|trente-cinq|trente-six|trente-sept|trente-huit|trente-neuf|quarante|quarante-et-un|quarante-deux|quarante-trois|quarante-quatre|quarante-cinq|quarante-six|quarante-sept|quarante-huit|quarante-neuf|cinquante)/ // "correction trente-cinq"
];

// Cache avec limite de taille
const recognitionCache = new Map();
const MAX_CACHE_SIZE = 100;

function addToCache(key, value) {
    // Limite la taille du cache
    if (recognitionCache.size >= MAX_CACHE_SIZE) {
        const firstKey = recognitionCache.keys().next().value;
        recognitionCache.delete(firstKey);
    }
    recognitionCache.set(key, value);
}

// Debounce pour √©viter updates DOM trop fr√©quentes
function debounce(func, wait) {
    let timeout;
    return function executedFunction(...args) {
        const later = () => {
            clearTimeout(timeout);
            func(...args);
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
}

// Version debounced de updateRepDisplayModern
// Utiliser la version globale si disponible, sinon cr√©er une version locale
const debouncedVoiceDisplay = window.debouncedUpdateDisplay || debounce((count, target, options) => {
    if (window.updateRepDisplayModern) {
        window.updateRepDisplayModern(count, target, options);
    }
}, 150); // 150ms si pas de version globale


// SYST√àME DE PR√âDICTION
let predictedNext = 1;
let displayedCount = 0;
let pendingValidation = null;


// PHASE 4 - Variables interpolation et validation renforc√©e
let interpolationInProgress = false;
let interpolationIndex = 0;
let originalGapsArray = [];
let interpolationAnimationSpeed = 300; // ms entre chaque gap

// √âtats validation renforc√©e
const VALIDATION_LEVELS = {
    STRICT: 'strict',      // Saut max +3, pas de r√©p√©titions
    PERMISSIVE: 'permissive' // Mode actuel tol√©rant
};

let validationMode = VALIDATION_LEVELS.STRICT; // Mode par d√©faut Phase 4

// √âtats visuels du micro
let currentMicState = 'inactive';

// Cache DOM pour √©viter querySelector r√©p√©titifs
let domCache = {
    voiceContainer: null,
    voiceIcon: null,
    voiceBtn: null,
    currentRepEl: null,
    targetRepEl: null
};

// Gestionnaire centralis√© des timers
const timers = {
    validation: null,
    autoValidation: null,
    correction: null,
    
    set(name, timer) {
        this.clear(name);  // Clear ancien timer
        this[name] = timer;
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Timers] ${name} d√©fini`);
    },
    
    clear(timerName) {
        if (this[timerName]) {
            clearTimeout(this[timerName]);
            this[timerName] = null;
        }
    },
    
    clearAll() {
        Object.keys(this).forEach(key => {
            if (typeof this[key] === 'number') {
                clearTimeout(this[key]);
                this[key] = null;
            }
        });
    }
};

// ===== VARIABLES ANDROID =====
const PLATFORM_CONFIG = {
    isAndroid: /Android/i.test(navigator.userAgent),
    android: {
        maxRestarts: 50,        // 30 ‚Üí 50 (s√©ries plus longues)
        restartDelay: 50,       // 300 ‚Üí 50 (utiliser cette valeur)
        duplicateWindow: 1500,  // 2000 ‚Üí 1500 (plus r√©actif)
        sessionTimeout: 300000, // 180000 ‚Üí 300000 (5 minutes)
        cleanupDelay: 500
    }
};

let androidRestartCount = 0;
let androidSessionStartTime = 0;
let androidRestartTimer = null;
let androidLastTranscripts = [];

// Syst√®me de logs conditionnels
const VOICE_DEBUG_LEVEL = {
    NONE: 0,      // Aucun log
    CRITICAL: 1,  // Erreurs seulement  
    NORMAL: 2,    // Op√©rations importantes
    VERBOSE: 3    // Tout (debug)
};

// En production : NORMAL, en debug : VERBOSE
let currentDebugLevel = window.location.hostname === 'localhost' ? 
    VOICE_DEBUG_LEVEL.VERBOSE : VOICE_DEBUG_LEVEL.NORMAL;

function voiceLog(level, ...args) {
    if (level <= currentDebugLevel) {
        console.log(...args);
    }
}

// Initialiser le cache une seule fois
function initDOMCache() {
    domCache.voiceContainer = document.getElementById('voiceStatusContainer');
    if (domCache.voiceContainer) {
        domCache.voiceIcon = domCache.voiceContainer.querySelector('#voiceStatusIcon');
        domCache.voiceBtn = domCache.voiceContainer.querySelector('#voiceStatusBtn');
    }
    domCache.currentRepEl = document.getElementById('currentRep');
    domCache.targetRepEl = document.getElementById('targetRep');
}

// V√©rifier les permissions au d√©marrage des s√©ances
async function checkMicrophonePermissions() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        return false;
    }
    
    try {
        const result = await navigator.permissions.query({ name: 'microphone' });
        
        if (result.state === 'granted') {
            return true;
        } else if (result.state === 'denied') {
            return false;
        } else {
            return true; // √âtat 'prompt' 
        }
    } catch (e) {
        return true; // Fallback
    }
}

// Masquer l'indicateur micro (appel√© en fin de s√©ance)
function hideVoiceStatus() {
    const container = document.getElementById('voiceStatusContainer');
    if (container) {
        container.style.display = 'none';
    }
}

// Exposer globalement
window.hideVoiceStatus = hideVoiceStatus;

// Met √† jour l'√©tat visuel du microphone - {'inactive'|'listening'|'processing'|'error'} state - √âtat du micro
// Version optimis√©e avec cache DOM et RAF
function updateMicrophoneVisualState(state) {
    if (!domCache.voiceContainer) {
        initDOMCache();
        if (!domCache.voiceContainer) return;
    }
    
    // √âviter updates inutiles
    if (currentMicState === state) return;
    
    // Utiliser requestAnimationFrame pour regrouper les updates DOM
    requestAnimationFrame(() => {
        const { voiceContainer, voiceIcon, voiceBtn } = domCache;
        // Reset classes en une seule op√©ration :
        voiceBtn.className = 'voice-status-btn';
        voiceIcon.className = ''; // AJOUTER CETTE LIGNE pour reset complet
                
        // Switch optimis√© avec moins d'op√©rations DOM
        switch(state) {
            case 'inactive':
                voiceIcon.className = 'fas fa-microphone';
                voiceIcon.style.color = '#6b7280';
                voiceBtn.classList.remove('pulse', 'shake', 'shake-error');
                break;
                
            case 'listening':
                voiceIcon.className = 'fas fa-microphone';
                voiceIcon.style.color = '#22c55e';
                voiceBtn.classList.add('pulse'); // Animation sur le bouton
                break;
                
            case 'ready':
                voiceIcon.className = 'fas fa-microphone';
                voiceIcon.style.color = '#3b82f6';
                voiceIcon.style.opacity = '0.8';
                voiceBtn.classList.add('shake');
                break;
                
            case 'error':
                voiceIcon.className = 'fas fa-microphone-slash';
                voiceIcon.style.color = '#ef4444';
                voiceBtn.classList.add('shake-error');
                break;
        }
        
        currentMicState = state;
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] √âtat visuel micro: ${state}`);
    });
}

// ===== FONCTIONS PRINCIPALES =====

/**
 * Initialise le module de reconnaissance vocale
 * V√©rifie la compatibilit√© du navigateur et configure l'instance
 * 
 * @returns {boolean} true si l'initialisation r√©ussit, false sinon
 */
function initVoiceRecognition() {
    // Initialiser le cache DOM d√®s le d√©but
    initDOMCache();
    // V√©rifier le support de la reconnaissance vocale
    if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
        console.warn('[Voice] Speech Recognition non support√©e par ce navigateur');
        return false;
    }
    
    try {
        // Cr√©er l'instance de reconnaissance vocale
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
                
        recognition.onstart = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Recognition STARTED', {
                timestamp: new Date().toISOString(),
                continuous: recognition.continuous,
                lang: recognition.lang
            });
        };

        recognition.onspeechstart = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Speech START detected');
        };

        recognition.onspeechend = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Speech END detected');
        };

        recognition.onaudiostart = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Audio START');
        };

        recognition.onaudioend = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Audio END');
        };

        // Configuration de base
        recognition.lang = 'fr-FR';
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.maxAlternatives = 3;
        
        // Attacher les gestionnaires d'√©v√©nements
        recognition.onresult = handleVoiceResult;
        recognition.onerror = handleVoiceError;
        recognition.onend = handleVoiceEnd;
        recognition.onstart = () => {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance d√©marr√©e');
        };
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Module initialis√© avec succ√®s');
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Langue configur√©e:', recognition.lang);
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Mode continu:', recognition.continuous);
        
        return true;
        
    } catch (error) {
        console.error('[Voice] Erreur lors de l\'initialisation:', error);
        return false;
    }
}

/**
 * G√®re les erreurs de d√©marrage de la reconnaissance vocale
 */
function handleVoiceStartupError(error) {
    console.error('[Voice] D√©tail erreur d√©marrage:', error);
    
    // D√©sactiver le comptage vocal pour cette session
    voiceRecognitionActive = false;
    
    // Messages explicites selon l'erreur
    if (error.name === 'NotAllowedError' || error.message.includes('permission')) {
        showToast('Permission microphone refus√©e. Activez-la dans les param√®tres du navigateur.', 'error');
        
        // Guide utilisateur
        setTimeout(() => {
            showToast('Chrome: cliquez sur üîí dans la barre d\'adresse ‚Üí Autoriser le microphone', 'info');
        }, 3000);
        
    } else if (error.name === 'NotFoundError') {
        showToast('Aucun microphone d√©tect√© sur cet appareil', 'error');
        
    } else if (error.name === 'NotSupportedError') {
        showToast('Reconnaissance vocale non support√©e par ce navigateur', 'error');
        
    } else {
        showToast('Erreur microphone. Utilisez le comptage manuel.', 'warning');
    }
    
    // Nettoyer l'interface
    const microIcon = document.querySelector('.voice-toggle-container i');
    if (microIcon) {
        microIcon.classList.remove('active');
    }
}


let autoValidationTimer = null;
let lastVoiceActivityTime = null;

/**
 * D√©marre le timer d'auto-validation (30s apr√®s derni√®re activit√© vocale)
 */
function startAutoValidationTimer() {
    // Nettoyer le timer existant
    if (autoValidationTimer) {
        clearTimeout(autoValidationTimer);
    }
    
    lastVoiceActivityTime = Date.now();
    
    // Timer de 30 secondes
    autotimers.set('validation', setTimeout(() => {
        handleAutoValidation();
    }, 30000));
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Timer auto-validation d√©marr√© (30s)');
}

/**
 * Remet √† z√©ro le timer √† chaque activit√© vocale
 */
function resetAutoValidationTimer() {
    if (!voiceRecognitionActive) return;
    
    lastVoiceActivityTime = Date.now();
    
    // Red√©marrer le timer
    if (autoValidationTimer) {
        clearTimeout(autoValidationTimer);
    }
    
    autotimers.set('validation', setTimeout(() => {
        handleAutoValidation();
    }, 30000));
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Timer auto-validation remis √† z√©ro');
}

/**
 * G√®re l'auto-validation apr√®s timeout
 */
function handleAutoValidation() {
    if (!voiceRecognitionActive || executionInProgress) {
        return;
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Timeout atteint - auto-validation');
    
    // Marquer l'ex√©cution en cours
    executionInProgress = true;
    
    // Arr√™ter la reconnaissance
    stopVoiceRecognition();
    
    // Valider avec le compte actuel
    if (voiceData.count > 0) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Auto-validation avec ${voiceData.count} r√©p√©titions`);
        
        // D√©clencher executeSet() si disponible
        if (typeof window.executeSet === 'function') {
            window.executeSet();
        }
    }
    
    // Reset flag apr√®s d√©lai
    setTimeout(() => {
        executionInProgress = false;
    }, 2000);
}

/**
 * Arr√™te la reconnaissance vocale et finalise les donn√©es
 * Version compl√®te avec nettoyage et export global
 */
function stopVoiceRecognition() {
    if (!voiceRecognitionActive) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance d√©j√† inactive');
        return;
    }
    
    try {
        recognition.stop();
        voiceRecognitionActive = false;
        
        // √âTAT VISUEL - SOURCE UNIQUE
        updateMicrophoneVisualState('inactive');
        
        // Cleanup timers
        clearAutoValidationTimer();
        timers.clear('correction');
        
        // Calcul confiance finale
        voiceData.confidence = calculateConfidence();
        
        // Exposition pour executeSet
        window.voiceData = voiceData;
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance arr√™t√©e');
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Donn√©es finales:', {
            count: voiceData.count,
            confidence: voiceData.confidence.toFixed(2)
        });
        
    } catch (error) {
        console.error('[Voice] Erreur arr√™t:', error);
        voiceRecognitionActive = false;
        updateMicrophoneVisualState('inactive');
    }
}

/**
 * Nettoie le timer d'auto-validation
 */
function clearAutoValidationTimer() {
    timers.clear('autoValidation');
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Timer auto-validation supprim√©');
}

/**
 * D√©marre la reconnaissance avec syst√®me de pr√©diction initialis√©
 */
function startVoiceRecognition() {
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Platform check:', {
        isAndroid: PLATFORM_CONFIG?.isAndroid,
        userAgent: navigator.userAgent,
        platformConfigExists: typeof PLATFORM_CONFIG !== 'undefined'
    });
    // PROTECTION RENFORC√âE
    if (voiceRecognitionActive) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance d√©j√† active - √©tat synchronis√©');
        updateMicrophoneVisualState('listening'); // Synchroniser visuel
        return true; // ‚Üê CRUCIAL : retourner true, pas false
    }
    
    if (!recognition) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Instance manquante, initialisation...');
        const initSuccess = initVoiceRecognition();
        if (!initSuccess || !recognition) {
            console.error('[Voice] Impossible de cr√©er instance recognition');
            updateMicrophoneVisualState('error');
            return false;
        }
    }
    
    // V√©rification utilisateur autorise vocal
    if (!currentUser?.voice_counting_enabled) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Comptage vocal d√©sactiv√© pour cet utilisateur');
        showToast('Comptage vocal d√©sactiv√©', 'info');
        return false;
    }
    
    // Cleanup modes conflictuels
    passiveListening = false;
    correctionMode = false;
    timers.clear('correction');
    
    // Reset donn√©es
    voiceData = {
        count: 0,
        timestamps: [],
        gaps: [],
        lastNumber: 0,
        startTime: Date.now(),
        confidence: 1.0
    };
    
    // Reset flags
    executionInProgress = false;
    predictedNext = 1;
    displayedCount = 0;
    pendingValidation = null;
    if (recognitionCache.size > MAX_CACHE_SIZE / 2) {
        recognitionCache.clear();
    }
    
    try {
        recognition.start();
        voiceRecognitionActive = true;
        // Configuration Android
        if (PLATFORM_CONFIG.isAndroid) {
            androidRestartCount = 0;
            androidSessionStartTime = Date.now();
            androidLastTranscripts = [];
            
            // Informer l'utilisateur
            showToast('Mode Android : red√©marrage automatique du micro', 'info');
            
            // Cleanup listeners
            window.addEventListener('beforeunload', cleanupAndroidResources);
            document.addEventListener('visibilitychange', handleVisibilityChange);
        }
                
        // √âTAT VISUEL - ICI √Ä LA FIN
        updateMicrophoneVisualState('listening');
        
        // Exposer globalement
        window.voiceData = voiceData;
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance d√©marr√©e avec succ√®s');
        return true;
        
    } catch (error) {
        console.error('[Voice] Erreur d√©marrage:', error);
        voiceRecognitionActive = false;
        updateMicrophoneVisualState('error');
        return false;
    }
}

/**
 * Gestionnaire principal des r√©sultats de reconnaissance
 * Parse les transcripts et identifie les nombres/commandes
 * 
 * @param {SpeechRecognitionEvent} event - √âv√©nement de reconnaissance
 * @returns {void}
 */
function handleVoiceResult(event) {
    const result = event.results[event.results.length - 1];
    const transcript = result[0].transcript.toLowerCase().trim();
    
    // NOUVELLE LOGIQUE : identifier ce qui a chang√©
    if (!result.isFinal) {
        // Traitement interim SEULEMENT pour pr√©diction imm√©diate
        handleInterimResult(transcript);
    } else {
        // Traitement final SEULEMENT pour validation d√©finitive
        handleFinalResult(transcript);
    }
}


/**
 * Traite les r√©sultats interm√©diaires pour affichage imm√©diat
 */
let lastInterimTime = 0;
function handleInterimResult(transcript) {
    // Limiter √† 5 updates par seconde max
    const now = Date.now();
    if (now - lastInterimTime < 200) return;
    lastInterimTime = now;
    // Ne traiter QUE si c'est exactement le nombre pr√©dit
    const cleanTranscript = transcript.trim();
    
    // Parsing rapide pour nombre unique
    const number = parseNumber(cleanTranscript);
    
    if (number && number > voiceData.count) {
        handleNumberDetected(number);
    }
}

/**
 * Traite les r√©sultats finaux pour validation d√©finitive
 */
function handleFinalResult(transcript) {
    // D√©tection de doublons Android
    if (PLATFORM_CONFIG.isAndroid && isAndroidDuplicate(transcript)) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Doublon d√©tect√©, ignor√©:', transcript);
        return;
    }
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Final:', transcript);
    
    // 1. V√©rifier cache (existant)
    if (recognitionCache.has(transcript)) {
        const cachedNumber = recognitionCache.get(transcript);
        if (cachedNumber) {
            processValidatedNumber(cachedNumber);
            return;
        }
    }
    
    // 2. PRIORIT√â : D√©tecter commandes de fin AVANT les nombres
    const hasEndCommand = transcript.includes('termin√©') || 
                         transcript.includes('fini') || 
                         transcript.includes('stop') || 
                         transcript.includes('fin');
    
    // 3. Extraire et traiter les nombres
    const numbers = extractNumbersFromTranscript(transcript);
    
    if (numbers.length > 0) {
        // Traiter tous les nombres
        for (const number of numbers) {
            if (number !== pendingValidation) {
                processValidatedNumber(number);
            }
        }
        
        // Mettre en cache le dernier nombre
        const lastNumber = numbers[numbers.length - 1];
        recognitionCache.set(transcript, lastNumber);
    }
    
    // 4. Si commande de fin d√©tect√©e, la traiter APR√àS les nombres
    if (hasEndCommand) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Commande fin d√©tect√©e apr√®s traitement nombres');
        // Petit d√©lai pour s'assurer que l'UI est √† jour
        setTimeout(() => {
            handleEndCommand();
        }, 100);
        return;
    }
    
    // 5. Autres d√©tections (inchang√©)
    if (pendingValidation && transcript.includes(pendingValidation.toString())) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation confirm√©e:', pendingValidation);
        pendingValidation = null;
        return;
    }
    
    if (transcript.includes('top') || transcript.includes('hop')) {
        handleKeywordDetected();
        return;
    }
    
    // Tentative de correction
    if (handleCorrection(transcript)) {
        return;
    }
}

let executionInProgress = false; // Flag pour √©viter double ex√©cution

/**
 * G√®re les commandes de fin avec protection anti-double
 */
function handleEndCommand() {
    if (executionInProgress) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Fin d√©j√† en cours, ignorer');
        return;
    }
    
    executionInProgress = true;
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Commande de fin d√©tect√©e');
    
    // Arr√™ter reconnaissance vocale et calculer confiance finale
    stopVoiceRecognition();
    
    const finalConfidence = calculateConfidence();
    voiceData.confidence = finalConfidence;
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Confiance finale calcul√©e: ${(finalConfidence * 100).toFixed(1)}%`);
    
    // Pr√©parer les donn√©es
    voiceData.validated = false; // Important : pas encore valid√©
    window.voiceData = voiceData;
    window.voiceState = voiceState;
    
    // D√©cision bas√©e sur confiance ET gaps
    // Tol√©rer 1 gap si confiance >= 85%, sinon 0 gap
    const acceptableGaps = finalConfidence >= 0.85 ? 1 : 0;
    if (finalConfidence >= 0.8 && voiceData.gaps.length <= acceptableGaps) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Confiance suffisante (${(finalConfidence*100).toFixed(1)}%) et gaps acceptables (${voiceData.gaps.length}/${acceptableGaps}) - Validation automatique`);
        
        // NE PAS marquer comme confirm√© ici - laisser confirmFinalCount() le faire
        voiceData.validated = false; // Sera mis √† true par confirmFinalCount
        voiceState = 'AUTO_VALIDATING'; // √âtat temporaire
        window.voiceData = voiceData;
        window.voiceState = voiceState;

        // Confirmer et d√©clencher executeSet automatiquement
        confirmFinalCount(voiceData.count);
                
    } else {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation manuelle requise - Confiance:', finalConfidence.toFixed(2), 'Gaps:', voiceData.gaps.length);
        
        // Afficher modal de validation - PAS DE TIMEOUT !
        voiceState = 'VALIDATING';
        window.voiceState = voiceState;
        
        showValidationModal(voiceData.count, finalConfidence);
        // PAS de setTimeout ici - attendre action utilisateur
    }
    
    // Reset mutex
    setTimeout(() => {
        executionInProgress = false;
    }, 2000);
}


/**
 * Extrait TOUS les nombres d'un transcript (ex: "1 2 3" -> [1,2,3])
 */
function extractNumbersFromTranscript(transcript) {
    const numbers = [];
    const words = transcript.split(/\s+/);
    
    for (const word of words) {
        const number = parseNumber(word.trim());
        if (number) {
            numbers.push(number);
        }
    }
    
    return numbers.sort((a, b) => a - b); // Tri croissant
}


/**
 * Traite un nombre valid√© (unifie la logique)
 */
function processValidatedNumber(number) {
    // √âviter le double processing
    if (number === voiceData.count) {
        return; // D√©j√† trait√©
    }
    
    handleNumberDetected(number);
}


/**
 * Parse intelligent et optimis√© des nombres
 */
function parseNumber(text) {
    if (!text || text.length === 0) return null;
    
    // Nettoyer le texte
    const cleanText = text.trim().toLowerCase();
    
    // Short-circuit pour patterns fr√©quents
    if (QUICK_PATTERNS.has(cleanText)) {
        return parseInt(cleanText);
    }
    
    // Recherche exacte dans la map fran√ßaise
    if (FRENCH_NUMBERS.has(cleanText)) {
        return FRENCH_NUMBERS.get(cleanText);
    }
    
    // Recherche flexible (contient le mot)
    for (const [word, number] of FRENCH_NUMBERS) {
        if (cleanText === word) {
            return number;
        }
    }
    
    return null;
}

// Calcule le niveau de confiance des donn√©es vocales
// Score de confiance entre 0.1 et 1.0
let cachedConfidence = null;
let confidenceInvalidated = true;

function calculateConfidence() {
    // Cache hit si pas d'invalidation
    if (!confidenceInvalidated && cachedConfidence !== null) {
        console.log('[Voice] Confiance depuis cache:', (cachedConfidence * 100).toFixed(1) + '%');
        return cachedConfidence;
    }
    
    let score = 1.0;
    
    // Protection s√©ries trop courtes pour √©valuation fiable
    if (voiceData.count < 3) {
        score = 0.8; // Confiance r√©duite car √©chantillon insuffisant
        console.log(`[Confidence] S√©rie courte (${voiceData.count} reps) - Confiance limit√©e: 80%`);
    }
    
    // P√©nalit√© gaps bas√©e sur ratio - R√âALISTE et S√âV√àRE
    if (voiceData.gaps.length > 0 && voiceData.count > 0) {
        const gapRatio = voiceData.gaps.length / voiceData.count;
        const gapPenalty = Math.min(gapRatio * 1.2, 0.9); // L√©g√®rement moins s√©v√®re
        score -= gapPenalty;
        console.log(`[Confidence] Gaps: ${voiceData.gaps.length}/${voiceData.count} (${(gapRatio*100).toFixed(1)}%) - P√©nalit√©: -${(gapPenalty * 100).toFixed(1)}%`);
    }
    
    // P√©nalit√© sauts suspects
    if (voiceData.suspiciousJumps > 0) {
        const jumpPenalty = Math.min(voiceData.suspiciousJumps * 0.15, 0.25); // L√©g√®rement r√©duit
        score -= jumpPenalty;
        console.log(`[Confidence] P√©nalit√© sauts suspects: -${(jumpPenalty * 100).toFixed(1)}%`);
    }
    
    // P√©nalit√© r√©p√©titions
    if (voiceData.repetitions > 0) {
        const repPenalty = Math.min(voiceData.repetitions * 0.08, 0.15); // L√©g√®rement r√©duit
        score -= repPenalty;
        console.log(`[Confidence] P√©nalit√© r√©p√©titions: -${(repPenalty * 100).toFixed(1)}%`);
    }
    
    // Bonus tempo r√©gulier
    if (voiceData.timestamps.length >= 3) {
        const avgTempo = calculateAvgTempo(voiceData.timestamps);
        if (avgTempo && avgTempo > 800 && avgTempo < 3000) {
            const tempoBonus = 0.05; // 5% bonus pour tempo r√©gulier
            score += tempoBonus;
            console.log(`[Confidence] Bonus tempo r√©gulier (${avgTempo}ms): +${(tempoBonus * 100).toFixed(1)}%`);
        }
    }
    
    // Borner entre 0.1 et 1.0
    score = Math.max(0.1, Math.min(1.0, score));
    
    // Mettre en cache
    cachedConfidence = score;
    confidenceInvalidated = false;
    
    console.log(`[Confidence] Score final: ${(score * 100).toFixed(1)}%`);
    return score;
}


// ===== PHASE 4 - INTERPOLATION GAPS AVEC ANIMATIONS =====

/**
 * Interpole les gaps manqu√©s avec animations s√©quentielles
 * Fonction principale d'interpolation Phase 4
 * @returns {Promise<boolean>} true si interpolation accept√©e
 */
async function interpolateGapsWithAnimation() {
    if (voiceData.gaps.length === 0 || interpolationInProgress) {
        return true; // Pas de gaps ou d√©j√† en cours
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Gaps] D√©but interpolation: ${voiceData.gaps.length} gaps √† combler`);
    
    interpolationInProgress = true;
    originalGapsArray = [...voiceData.gaps]; // Sauvegarde pour rollback
    
    // Trier gaps par ordre croissant
    const sortedGaps = voiceData.gaps.sort((a, b) => a - b);
    
    try {
        // Animation s√©quentielle de chaque gap
        for (let i = 0; i < sortedGaps.length; i++) {
            interpolationIndex = i;
            const gap = sortedGaps[i];
            
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Gaps] Animation gap ${gap} (${i + 1}/${sortedGaps.length})`);
            
            // Animation visuelle gap combl√©
            await showGapInterpolation(gap, sortedGaps.length, i);
            
            // D√©lai entre animations pour fluidit√©
            if (i < sortedGaps.length - 1) {
                await new Promise(resolve => setTimeout(resolve, interpolationAnimationSpeed));
            }
        }
        
        // Confirmation utilisateur finale
        const accepted = await confirmGapInterpolation(voiceData.count, voiceData.count - sortedGaps.length, sortedGaps);
        
        if (!accepted) {
            // Rollback vers count original
            rollbackInterpolation();
            return false;
        }
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Gaps] Interpolation confirm√©e: ${voiceData.count} reps finales`);
        return true;
        
    } catch (error) {
        console.error('[Gaps] Erreur interpolation:', error);
        rollbackInterpolation();
        return false;
        
    } finally {
        interpolationInProgress = false;
        interpolationIndex = 0;
    }
}

/**
 * Affiche l'animation pour un gap sp√©cifique
 * @param {number} gapNumber - Num√©ro gap √† combler
 * @param {number} totalGaps - Total gaps √† interpoler
 * @param {number} currentIndex - Index progression
 * @returns {Promise<void>}
 */
async function showGapInterpolation(gapNumber, totalGaps, currentIndex) {
    const targetRepEl = document.getElementById('targetRep');
    const targetReps = targetRepEl ? parseInt(targetRepEl.textContent) : 12;
    
    // Animation distincte de l'interface N/R normale
    updateRepDisplayModern(gapNumber, targetReps, {
        interpolating: true,
        interpolationProgress: `${currentIndex + 1}/${totalGaps}`
    });
    
    // Vibration diff√©renci√©e pour interpolation
    if (navigator.vibrate) {
        navigator.vibrate([50, 30, 50]); // Pattern vibration interpolation
    }
    
    // Log pour debug
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Gaps] Gap ${gapNumber} interpol√© visuellement`);
    
    // Attendre fin animation CSS
    await new Promise(resolve => setTimeout(resolve, 200));
}

/**
 * Feedback erreur am√©lior√© Phase 4
 * @param {string} errorType - Type erreur d√©taill√©
 * @param {Object} details - Contexte erreur
 */
function enhancedErrorFeedback(errorType, details = {}) {
    // Interface N/R avec erreur sp√©cifique
    const targetRepEl = document.getElementById('targetRep');
    const targetReps = targetRepEl ? parseInt(targetRepEl.textContent) : 12;
   
    const options = {
        voiceError: true,
        errorType: errorType
    };
    
    // Utiliser la version globale ou fallback
    const updateDisplay = window.debouncedUpdateDisplay || window.updateRepDisplayModern;
   
    // Feedback diff√©renci√© selon type erreur
    switch (errorType) {
        case 'jump_too_large':
            options.errorMessage = `Saut trop grand: +${details.jump}`;
            updateDisplay(voiceData.count, targetReps, options);
            // Double vibration pour erreur grave
            if (navigator.vibrate) navigator.vibrate([100, 50, 100]);
            break;
           
        case 'repetition':
            options.errorMessage = `R√©p√©tition: ${details.repeatedNumber}`;
            updateDisplay(voiceData.count, targetReps, options);
            // Vibration simple pour r√©p√©tition
            if (navigator.vibrate) navigator.vibrate(150);
            break;
           
        case 'backward_count':
            options.errorMessage = 'Compte arri√®re d√©tect√©';
            updateDisplay(voiceData.count, targetReps, options);
            // Triple vibration pour erreur logique
            if (navigator.vibrate) navigator.vibrate([80, 30, 80, 30, 80]);
            break;
           
        default:
            updateDisplay(voiceData.count, targetReps, options);
            if (navigator.vibrate) navigator.vibrate(100);
    }
   
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Feedback] Erreur ${errorType} signal√©e visuellement`);
}

// Rollback interpolation en cas d'annulation
function rollbackInterpolation() {
    if (originalGapsArray.length > 0) {
        voiceData.gaps = [...originalGapsArray];
        voiceData.count = voiceData.count - originalGapsArray.length;
        
        // Restaurer interface
        const targetRepEl = document.getElementById('targetRep');
        const targetReps = targetRepEl ? parseInt(targetRepEl.textContent) : 12;
        debouncedVoiceDisplay(voiceData.count, targetReps);
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Gaps] Rollback effectu√©: count restaur√© √† ${voiceData.count}`);
    }
}

function showValidationModal(count, confidence) {
    // Nettoyer tout modal existant
    const existingModal = document.getElementById('voice-validation-modal');
    if (existingModal) existingModal.remove();
    
    // Cr√©er overlay
    const overlay = document.createElement('div');
    overlay.id = 'voice-validation-modal';
    overlay.className = 'voice-validation-modal';
    overlay.innerHTML = `
        <div class="voice-modal-content">
            <h3>Valider le nombre de r√©p√©titions</h3>
            
            <div class="voice-count-display">
                <button class="count-btn minus" onclick="adjustModalCount(-1)">‚àí</button>
                <span class="count-value" id="modalCount">${count}</span>
                <button class="count-btn plus" onclick="adjustModalCount(1)">+</button>
            </div>
            
            <div class="voice-info">
                <p class="confidence-text">Confiance: ${(confidence * 100).toFixed(0)}%</p>
                ${voiceData.gaps.length > 0 ? 
                    `<p class="gaps-text">R√©p√©titions manqu√©es: ${voiceData.gaps.join(', ')}</p>` : 
                    ''}
            </div>
            
            <div class="modal-actions">
                <button class="btn-validate" onclick="validateVoiceCount()">
                    Valider ${count} r√©p√©titions
                </button>
            </div>
            
            <p class="help-text">Ajustez si n√©cessaire puis validez</p>
        </div>
    `;
    
    document.body.appendChild(overlay);
    
    // Animation d'entr√©e
    requestAnimationFrame(() => {
        overlay.classList.add('visible');
    });
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Modal validation affich√© - Count: ${count}, Confiance: ${confidence.toFixed(2)}`);
}

// Fonction pour ajuster le count dans le modal
window.adjustModalCount = function(delta) {
    const countEl = document.getElementById('modalCount');
    if (!countEl) return;
    
    let currentCount = parseInt(countEl.textContent);
    let newCount = Math.max(0, Math.min(50, currentCount + delta));
    
    countEl.textContent = newCount;
    
    // Mettre √† jour le bouton
    const btnValidate = document.querySelector('.btn-validate');
    if (btnValidate) {
        btnValidate.textContent = `Valider ${newCount} r√©p√©titions`;
    }
    
    // Vibration feedback
    if (navigator.vibrate) navigator.vibrate(20);
};

// Fonction pour valider depuis le modal
window.validateVoiceCount = function() {
    const count = parseInt(document.getElementById('modalCount').textContent);
    const modal = document.getElementById('voice-validation-modal');
    
    // Animation de sortie
    modal.classList.remove('visible');
    
    setTimeout(() => {
        modal.remove();
        
        // Confirmer le count
        voiceData.count = count;
        voiceData.validated = true;
        voiceState = 'CONFIRMED';
        window.voiceData = voiceData;
        window.voiceState = voiceState;
        
        confirmFinalCount(count);
        // D√©clencher automatiquement executeSet apr√®s validation manuelle
        setTimeout(() => {
            if (typeof window.executeSet === 'function') {
                window.executeSet();
            }
        }, 100);
    }, 300);
};

/**
 * Ajuste le count vocal via les boutons +/-
 * Interaction rapide et responsive
 * 
 * @param {number} delta - Changement (-1 ou +1)
 */
function adjustVoiceCount(delta) {
    const countElement = document.querySelector('.voice-count');
    if (!countElement) return;
    
    const currentCount = parseInt(countElement.textContent);
    const newCount = Math.max(0, Math.min(50, currentCount + delta));
    
    // Mise √† jour imm√©diate
    countElement.textContent = newCount;
    voiceData.count = newCount;
    
    // Reset timer sur interaction utilisateur
    resetValidationTimer(newCount);
    
    // Feedback vibration sur mobile
    if (navigator.vibrate) {
        navigator.vibrate(20);
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Count ajust√©: ${currentCount} ‚Üí ${newCount}`);
}

/**
 * D√©termine la classe CSS selon le niveau de confiance
 * 
 * @param {number} confidence - Score de confiance (0-1)
 * @returns {string} Nom de classe CSS
 */
function getConfidenceClass(confidence) {
    if (confidence >= CONFIDENCE_LEVELS.HIGH) {
        return 'voice-high-confidence';
    } else if (confidence >= CONFIDENCE_LEVELS.MEDIUM) {
        return 'voice-medium-confidence';
    } else {
        return 'voice-low-confidence';
    }
}

/**
 * D√©marre le timer d'auto-validation
 * 
 * @param {number} count - Count √† confirmer automatiquement
 */
function startValidationTimer(count) {
    voiceState = 'VALIDATING';
    
    timers.set('validation', setTimeout(() => {
        confirmVoiceCount(count);
    }, 4000)); // 4s pour validation manuelle
}

/**
 * Reset le timer de validation sur interaction utilisateur
 * 
 * @param {number} newCount - Nouveau count apr√®s ajustement
 */
function resetValidationTimer(newCount) {
    if (validationTimer) {
        clearTimeout(validationTimer);
    }
    
    // Nouveau timer avec le count ajust√©
    timers.set('validation', setTimeout(() => {
        confirmVoiceCount(newCount);
    }, 2000)); // 2s apr√®s interaction
}

/**
 * Confirme le count final et nettoie l'interface
 * 
 * @param {number} finalCount - Count d√©finitif
 */
function confirmVoiceCount(finalCount) {
    // NOUVEAU - Emp√™cher double confirmation
    if (voiceState === 'CONFIRMED') {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] D√©j√† confirm√©, ignore');
        return;
    }
    
    // NOUVEAU - Arr√™ter √©coute passive avant confirmation
    if (VOICE_FEATURES.voice_correction) {
        stopPassiveListening();
    }

    voiceData.count = finalCount;
    voiceState = 'CONFIRMED';
    
    // Nettoyer l'interface
    clearValidationUI();
    
    // Exposer pour executeSet
    window.voiceData = voiceData;
    window.voiceState = voiceState;  // AJOUTER cette ligne
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Count confirm√©: ${finalCount} - √âtat: ${voiceState}`);
    
    // Auto-trigger executeSet si activ√© dans √©tapes futures
    if (VOICE_FEATURES.auto_validation && typeof window.executeSet === 'function') {
        setTimeout(window.executeSet, 100);
    }
}

/**
 * Nettoie l'interface de validation
 */
function clearValidationUI() {
    const repsElement = document.getElementById('setReps');
    if (!repsElement) return;
    
    // Restaurer contenu original
    const original = repsElement.getAttribute('data-original');
    if (original) {
        repsElement.textContent = original;
        repsElement.removeAttribute('data-original');
    }
    
    // Nettoyer styles
    repsElement.className = '';
    repsElement.style.transform = '';
    repsElement.style.color = '';
    repsElement.style.border = '';
    
    // REMETTRE CACH√â
    repsElement.style.display = 'none';
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] √âl√©ment setReps remis en mode cach√©');
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Interface validation nettoy√©e');
}

/**
 * Valide un saut de nombre et d√©tecte les patterns suspects
 * 
 * @param {number} newNumber - Nouveau nombre d√©tect√©
 * @param {number} lastDetected - Dernier nombre explicitement d√©tect√©
 * @returns {Object} {valid: boolean, suspicious: boolean, reason?: string}
 */
function validateNumberJump(newNumber, lastDetected) {
    const jump = newNumber - lastDetected;
    
    // Validation de base
    if (jump <= 0) {
        return { valid: false, reason: 'Nombre d√©j√† atteint ou en arri√®re' };
    }
    
    if (jump > 8) {
        return { valid: false, reason: `Saut trop important: +${jump}` };
    }
    
    // D√©tection de pattern suspect
    const suspicious = jump === 3; // Saut exactement de +3
    
    return { 
        valid: true, 
        suspicious: suspicious,
        jump: jump
    };
}

/**
 * Affichage imm√©diat optimis√© (sans animation lourde)
 */
function updateVoiceDisplayImmediate(count) {
    const repsElement = document.getElementById('setReps');
    if (repsElement) {
        repsElement.textContent = count;
        // Animation l√©g√®re mais imm√©diate
        repsElement.style.transform = 'scale(1.05)';
        repsElement.style.color = 'var(--primary)';
        
        setTimeout(() => {
            repsElement.style.transform = '';
            repsElement.style.color = '';
        }, 150);
    }
}

/**
 * G√®re la d√©tection d'un nombre dans la reconnaissance vocale
 * 
 * @param {number} number - Nombre d√©tect√©
 * @returns {void}
 */
/**
 * G√®re la d√©tection d'un nombre dans la reconnaissance vocale
 * VERSION OPTIMIS√âE avec gestion gaps intelligente + debouncing + cache confidence
 * 
 * @param {number} number - Nombre d√©tect√©
 * @returns {void}
 */
function handleNumberDetected(number) {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Nombre d√©tect√©: ${number}`);
    
    // OPT-B : Invalider le cache de confiance
    confidenceInvalidated = true;
    
    // Validation de base existante - INCHANG√âE
    const expectedNext = voiceData.lastNumber + 1;
    const jump = number - voiceData.lastNumber;
    
    if (jump > 10) {
        console.warn(`[Voice] Saut trop important ignor√©: ${voiceData.lastNumber} -> ${number}`);
        voiceData.suspiciousJumps++;
        
        // Feedback discret passif
        if (window.showToast) {
            window.showToast(`Saut important d√©tect√© (+${jump})`, 'warning');
        }
        if (navigator.vibrate) {
            navigator.vibrate([100, 50, 100]);
        }
        return;
    }
    
    // D√©tection r√©p√©tition - INCHANG√âE avec feedback discret
    if (number === voiceData.lastNumber && voiceData.count > 0) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] R√©p√©tition d√©tect√©e');
        voiceData.repetitions++;
        
        if (voiceData.repetitions > 2) {
            // Feedback discret
            if (window.showToast) {
                window.showToast(`R√©p√©tition du ${number}`, 'info');
            }
            if (navigator.vibrate) {
                navigator.vibrate([50, 30, 50]);
            }
        }
        return;
    }
    
    // Reset r√©p√©titions - INCHANG√â
    if (number !== voiceData.lastNumber) {
        voiceData.repetitions = 0;
    }
    
    // OPTIM 6 : Gestion gaps intelligente avec v√©rification tempo
    if (jump > 1 && jump <= 10) {
        // NOUVEAU : V√©rifier tempo avant de marquer comme gap
        const tempo = calculateAvgTempo(voiceData.timestamps);
        if (jump <= 2 && tempo && tempo > 500 && tempo < 2000) {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Gap ignor√© (tempo r√©gulier ${tempo}ms): ${expectedNext} √† ${number-1}`);
            // Ne pas ajouter aux gaps - comptage r√©gulier d√©tect√©
        } else {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Gap d√©tect√©: ${expectedNext} √† ${number-1}`);
            for (let i = expectedNext; i < number; i++) {
                if (!voiceData.gaps.includes(i)) {
                    voiceData.gaps.push(i);
                }
            }
            voiceData.needsValidation = true;
            
            // Feedback discret seulement
            const newGaps = number - expectedNext;
            if (window.showToast) {
                window.showToast(`${newGaps} r√©p√©tition${newGaps > 1 ? 's' : ''} saut√©e${newGaps > 1 ? 's' : ''}`, 'warning');
            }
            if (navigator.vibrate) {
                navigator.vibrate([80, 40, 80]);
            }
        }
    }
    
    // Mise √† jour normale - OPTIMIS√âE
    voiceData.count = number;
    voiceData.lastNumber = number;
    voiceData.timestamps.push(Date.now());
    voiceData.lastDetected = number;
    
    // OPT-A : Utiliser version debounc√©e pour √©viter reflow DOM excessifs
    debouncedUpdate(number);
    
    predictedNext = number + 1;

    // Mode passif = pas de validation forc√©e
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] √âtat passif: count=${voiceData.count}, gaps=[${voiceData.gaps}], confiance en cours de calcul...`);
}

function predictMissingNumbers(detectedNumber) {
    const expectedNext = voiceData.count + 1;
    
    // Si on d√©tecte un nombre > expectedNext, remplir automatiquement
    if (detectedNumber > expectedNext) {
        const tempo = calculateAverageTempo();
        const gapSize = detectedNumber - expectedNext;
        
        // Si tempo r√©gulier ET gap raisonnable, auto-remplir
        if (tempo < 2000 && gapSize <= 3) {
            for (let i = expectedNext; i < detectedNumber; i++) {
                handleNumberDetected(i, true); // true = predicted
            }
        }
    }
}

/**
 * Traite les commandes de correction vocale
 * Parse "correction N" avec nombres fran√ßais et chiffres
 * 
 * @param {string} transcript - Transcription contenant la correction
 * @returns {boolean} true si correction trait√©e, false sinon
 */
function handleCorrection(transcript) {
    if (!VOICE_FEATURES.voice_correction) {
        return false;
    }
    
    const cleanTranscript = transcript.toLowerCase().trim();
    
    for (const pattern of CORRECTION_PATTERNS) {
        const match = cleanTranscript.match(pattern);
        if (match) {
            const correctionValue = match[1];
            let newCount;
            
            // Parser nombre (chiffre ou mot fran√ßais)
            if (/^\d+$/.test(correctionValue)) {
                newCount = parseInt(correctionValue);
            } else {
                newCount = FRENCH_NUMBERS.get(correctionValue);
            }
            
            if (newCount !== undefined && newCount >= 0 && newCount <= 50) {
                applyCorrectionCount(newCount);
                return true;
            }
        }
    }
    
    return false;
}

/**
 * D√©marre le processus d'auto-validation intelligent
 * Pattern optimis√©: Confiance HAUTE ‚Üí 1.5s, Confiance BASSE ‚Üí 4s
 */
function scheduleAutoValidation() {
    if (!VOICE_FEATURES.auto_validation) {
        return;
    }
    
    const confidence = calculateConfidence();
    voiceData.confidence = confidence;
    
    if (confidence >= CONFIDENCE_LEVELS.HIGH) {
        // Auto-validation rapide et discr√®te
        scheduleQuickValidation();
    } else {
        // Validation avec UI et temps suppl√©mentaire
        scheduleStandardValidation();
    }
}

/**
 * Auto-validation rapide pour confiance √©lev√©e (1.5s)
 */
function scheduleQuickValidation() {
    voiceState = 'AUTO_VALIDATING';
    
    // Indicateur discret
    showSubtleConfirmation(voiceData.count);
    
    timers.set('validation', setTimeout(() => {
        confirmFinalCount(voiceData.count);
    }, 1500)); // 1.5s pour confiance haute
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Auto-validation rapide programm√©e - Count: ${voiceData.count}, Confiance: ${voiceData.confidence.toFixed(2)}`);
}

/**
 * Validation standard avec UI pour confiance faible (4s)
 */
function scheduleStandardValidation() {
    voiceState = 'VALIDATING';
    
    // Afficher UI de validation si activ√©e
    if (VOICE_FEATURES.validation_ui) {
        showValidationModal(voiceData.count, voiceData.confidence);
    } else {
        // Mode legacy - simple indicateur
        showSubtleConfirmation(voiceData.count);
    }
    
    timers.set('validation', setTimeout(() => {
        confirmFinalCount(voiceData.count);
    }, 4000)); // 4s pour confiance faible
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Validation standard programm√©e - Count: ${voiceData.count}, Confiance: ${voiceData.confidence.toFixed(2)}`);
}

/**
 * Affiche une confirmation discr√®te sans UI lourde
 * 
 * @param {number} count - Count √† confirmer
 */
function showSubtleConfirmation(count) {
    const repsElement = document.getElementById('setReps');
    if (!repsElement) return;
    
    // Mise √† jour imm√©diate du count
    repsElement.textContent = count;
    
    // Animation discr√®te
    repsElement.classList.add('voice-confirming');
    repsElement.style.transform = 'scale(1.02)';
    repsElement.style.color = 'var(--success, #28a745)';
    
    setTimeout(() => {
        repsElement.style.transform = '';
        repsElement.style.color = '';
        repsElement.classList.remove('voice-confirming');
    }, 300);
}

/**
 * Confirme le count final et d√©clenche executeSet automatiquement
 * 
 * @param {number} finalCount - Count d√©finitif valid√©
 */
function confirmFinalCount(finalCount) {
    // Emp√™cher double confirmation
    if (voiceState === 'CONFIRMED' && voiceData.validated) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] D√©j√† confirm√©, ignore');
        return;
    }
    
    // Enregistrer m√©triques de validation
    const isAutoValidation = voiceState === 'AUTO_VALIDATING' || 
                            (voiceData.confidence >= 0.8 && voiceData.gaps.length === 0);
    const startTime = voiceData.startTime || Date.now();
    recordValidationMetrics(isAutoValidation, startTime);
    
    // Arr√™ter √©coute passive si active
    if (VOICE_FEATURES.voice_correction) {
        stopPassiveListening();
    }
    
    // Finaliser les donn√©es
    voiceData.count = finalCount;
    voiceData.needsValidation = false;
    voiceData.validated = true; // IMPORTANT: Marquer comme valid√©
    voiceState = 'CONFIRMED';
    
    // Nettoyer l'interface (modal ou ancienne UI)
    clearValidationUI();
    
    // Fermer le modal si pr√©sent
    const modal = document.getElementById('voice-validation-modal');
    if (modal) {
        modal.classList.remove('visible');
        setTimeout(() => modal.remove(), 300);
    }
    
    // INTERPOLATION SILENCIEUSE si gaps pr√©sents
    if (voiceData.gaps.length > 0) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] ${voiceData.gaps.length} gaps d√©tect√©s - Calcul interpolation silencieux`);
        
        // Calculer tempo moyen des reps existantes
        const avgTempo = calculateAvgTempo(voiceData.timestamps);
        
        // Cr√©er timestamps interpol√©s pour analyse ML
        const interpolatedTimestamps = [];
        let lastTime = voiceData.timestamps[0] || voiceData.startTime;
        
        for (let i = 1; i <= voiceData.count; i++) {
            if (voiceData.gaps.includes(i)) {
                // Gap: ajouter timestamp interpol√©
                lastTime += avgTempo;
                interpolatedTimestamps.push(lastTime);
            } else {
                // Rep r√©elle: utiliser timestamp existant
                const prevGaps = voiceData.gaps.filter(g => g < i).length;
                const realIndex = i - prevGaps - 1;
                
                if (realIndex >= 0 && realIndex < voiceData.timestamps.length) {
                    lastTime = voiceData.timestamps[realIndex];
                    interpolatedTimestamps.push(lastTime);
                }
            }
        }
        
        // Stocker les donn√©es interpol√©es pour ML
        voiceData.interpolated_timestamps = interpolatedTimestamps;
        voiceData.tempo_avg_interpolated = calculateAvgTempo(interpolatedTimestamps);
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Interpolation calcul√©e - Tempo interpol√©:', voiceData.tempo_avg_interpolated);
    }
    
    // Exposer globalement pour executeSet
    window.voiceData = voiceData;
    window.voiceState = voiceState;
    
    // D√âCISION CRITIQUE : executeSet automatique SEULEMENT si validation auto
    // C'est-√†-dire : confiance >= 0.8 ET pas de gaps ET pas depuis modal
    const wasAutoValidation = isAutoValidation && 
                             voiceData.confidence >= 0.8 && 
                             voiceData.gaps.length === 0;
    
    if (wasAutoValidation) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation automatique confirm√©e - D√©clenchement executeSet()');
        
        // Micro-d√©lai pour fluidit√© visuelle
        setTimeout(() => {
            if (typeof window.executeSet === 'function') {
                window.executeSet();
            }
            
            // Reset √©tat apr√®s ex√©cution
            setTimeout(() => {
                resetVoiceState();
            }, 200);
        }, 50);
        
    } else {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation manuelle - Affichage bouton executeSet');
        
        // Pour validation manuelle, juste afficher le bouton
        const executeBtn = document.getElementById('executeSetBtn');
        if (executeBtn) {
            executeBtn.style.display = 'block';
            
            // S'assurer que le bouton garde son apparence normale
            const emoji = executeBtn.querySelector('.go-emoji');
            if (emoji) {
                emoji.textContent = ''; // Garder l'emoji par d√©faut
            }
        }
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Count final confirm√©: ${finalCount} - √âtat: ${voiceState}, Valid√©: ${voiceData.validated}`);
}

/**
 * Remet √† z√©ro l'√©tat vocal apr√®s executeSet
 */
function resetVoiceState() {
    voiceState = 'LISTENING';
    voiceData = {
        count: 0,
        timestamps: [],
        gaps: [],
        lastNumber: 0,
        lastDetected: 0,
        startTime: null,
        confidence: 1.0,
        suspiciousJumps: 0,
        repetitions: 0,
        needsValidation: false
    };
    timers.clearAll(); // Nettoyer tous les timers
    // Nettoyer les variables globales
    window.voiceData = null;
    window.voiceState = 'LISTENING';
}

/**
 * Annule la validation vocale en cours
 * Utilis√©e par transitionTo() pour nettoyer l'√©tat
 */
function cancelVoiceValidation() {
    if (voiceState === 'LISTENING' || voiceState === 'CONFIRMED') {
        return; // Rien √† annuler
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Annulation validation en cours');
    
    // Nettoyer timers
    timers.clear('validation');
    
    // Arr√™ter √©coute passive
    if (VOICE_FEATURES.voice_correction) {
        stopPassiveListening();
    }
    
    // Nettoyer interface
    clearValidationUI();
    
    // Reset √©tat
    voiceState = 'LISTENING';
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation annul√©e, retour en mode √©coute');
}

/**
 * Collecte des m√©triques UX pour monitoring
 */
const voiceMetrics = {
    validationsTotal: 0,
    validationsAuto: 0,
    validationsManual: 0,
    averageValidationTime: 0,
    confidenceScores: [],
    
    recordValidation: function(isAuto, validationTime, confidence) {
        this.validationsTotal++;
        
        if (isAuto) {
            this.validationsAuto++;
        } else {
            this.validationsManual++;
        }
        
        this.confidenceScores.push(confidence);
        
        // Calculer temps moyen
        const totalTime = this.averageValidationTime * (this.validationsTotal - 1) + validationTime;
        this.averageValidationTime = totalTime / this.validationsTotal;
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] M√©triques:', this.getStats());
    },
    
    getStats: function() {
        const autoRate = this.validationsTotal > 0 ? 
            (this.validationsAuto / this.validationsTotal * 100).toFixed(1) : 0;
        
        const avgConfidence = this.confidenceScores.length > 0 ?
            (this.confidenceScores.reduce((a, b) => a + b, 0) / this.confidenceScores.length).toFixed(2) : 0;
        
        return {
            total: this.validationsTotal,
            autoRate: `${autoRate}%`,
            avgTime: `${this.averageValidationTime.toFixed(1)}s`,
            avgConfidence: avgConfidence
        };
    },
    
    reset: function() {
        this.validationsTotal = 0;
        this.validationsAuto = 0;
        this.validationsManual = 0;
        this.averageValidationTime = 0;
        this.confidenceScores = [];
    }
};

/**
 * Fonction de monitoring int√©gr√©e dans confirmFinalCount
 */
function recordValidationMetrics(isAuto, startTime) {
    const validationTime = (Date.now() - startTime) / 1000;
    voiceMetrics.recordValidation(isAuto, validationTime, voiceData.confidence);
}

/**
 * D√©marre l'√©coute passive pour corrections vocales
 * Optimis√© pour pr√©server la batterie
 */
function startPassiveListening() {
    if (!VOICE_FEATURES.voice_correction || passiveListening || !recognition) {
        return;
    }
    
    // V√©rifier l'√©tat avant de d√©marrer
    if (voiceRecognitionActive) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance d√©j√† active, pas de mode passif');
        return;
    }
    
    try {
        // Configuration l√©g√®re pour √©coute passive
        recognition.continuous = true;
        recognition.interimResults = false; // R√©duire le processing
        recognition.maxAlternatives = 1;   // R√©duire le processing
        
        // Handler sp√©cialis√© pour corrections
        recognition.onresult = handlePassiveResult;
        recognition.onerror = handlePassiveError;
        recognition.onend = handlePassiveEnd;
        
        recognition.start();
        passiveListening = true;
        correctionMode = true;
        
        // Timeout automatique pour pr√©server batterie
        correctionTimer = setTimeout(() => {
            stopPassiveListening();
        }, 10000); // 10s max d'√©coute passive
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] √âcoute passive d√©marr√©e pour corrections');
        
    } catch (error) {
        console.warn('[Voice] Impossible de d√©marrer √©coute passive:', error.message);
        passiveListening = false;
    }
}

/**
 * Traite les r√©sultats en mode √©coute passive
 * 
 * @param {SpeechRecognitionEvent} event
 */
function handlePassiveResult(event) {
    const result = event.results[event.results.length - 1];
    if (!result.isFinal) return;
    
    const transcript = result[0].transcript;
    
    // Traiter uniquement les corrections
    if (handleCorrection(transcript)) {
        // Correction trouv√©e et appliqu√©e
        return;
    }
    
    // V√©rifier commandes d'arr√™t
    const lowerTranscript = transcript.toLowerCase();
    if (lowerTranscript.includes('stop') || 
        lowerTranscript.includes('arr√™t') || 
        lowerTranscript.includes('termin√©')) {
        stopPassiveListening();
    }
}

/**
 * G√®re les erreurs en mode passif
 * 
 * @param {SpeechRecognitionError} event
 */
function handlePassiveError(event) {
    if (event.error === 'no-speech' || event.error === 'audio-capture') {
        // Erreurs normales en mode passif - continuer silencieusement
        return;
    }
    
    console.warn('[Voice] Erreur √©coute passive:', event.error);
    stopPassiveListening();
}

/**
 * G√®re la fin de l'√©coute passive
 */
function handlePassiveEnd() {
    if (passiveListening && correctionMode) {
        // Red√©marrer automatiquement si mode correction actif
        setTimeout(() => {
            if (correctionMode && passiveListening) {
                try {
                    recognition.start();
                } catch (error) {
                    stopPassiveListening();
                }
            }
        }, 100);
    }
}

/**
 * Arr√™te l'√©coute passive et nettoie les timers
 */
function stopPassiveListening() {
    if (!passiveListening) return;
    
    passiveListening = false;
    correctionMode = false;
    
    timers.clear('correction');
    
    try {
        if (recognition && voiceRecognitionActive) {
            recognition.stop();
        }
    } catch (error) {
        // Erreur silencieuse
    }
    
    // Restaurer configuration normale
    if (recognition) {
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.maxAlternatives = 3;
        recognition.onresult = handleVoiceResult;
        recognition.onerror = handleVoiceError;
        recognition.onend = handleVoiceEnd;
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] √âcoute passive arr√™t√©e');
}

/**
 * Valide les cas limites pour corrections vocales
 * 
 * @param {number} count - Count √† valider
 * @returns {Object} {valid: boolean, adjustedCount?: number, reason?: string}
 */
function validateCorrectionCount(count) {
    // Cas limite: correction 0
    if (count === 0) {
        return {
            valid: true,
            adjustedCount: 0,
            reason: 'Reset √† z√©ro autoris√©'
        };
    }
    
    // Cas limite: correction > 50
    if (count > 50) {
        return {
            valid: true,
            adjustedCount: 50,
            reason: 'Plafonn√© √† 50 reps maximum'
        };
    }
    
    // Cas limite: correction n√©gative
    if (count < 0) {
        return {
            valid: false,
            reason: 'Count n√©gatif impossible'
        };
    }
    
    // Validation suppl√©mentaire: saut tr√®s important
    const currentCount = voiceData.count;
    const jump = Math.abs(count - currentCount);
    
    if (jump > 20) {
        return {
            valid: true,
            adjustedCount: count,
            reason: `Correction importante: ${currentCount} ‚Üí ${count}`
        };
    }
    
    return { valid: true, adjustedCount: count };
}

/**
 * Version am√©lior√©e d'applyCorrectionCount avec validation
 * 
 * @param {number} rawCount - Count brut de la correction
 */
function applyCorrectionCount(rawCount) {
    const validation = validateCorrectionCount(rawCount);
    
    if (!validation.valid) {
        console.warn(`[Voice] Correction rejet√©e: ${validation.reason}`);
        return;
    }
    
    const newCount = validation.adjustedCount;
    const previousCount = voiceData.count;
    
    // Appliquer la correction
    voiceData.count = newCount;
    
    // Mise √† jour interface
    updateCorrectionUI(newCount, previousCount);
    
    // Feedback utilisateur
    if (navigator.vibrate) {
        navigator.vibrate([50, 50, 50]);
    }
    
    // Log avec d√©tails
    const logMessage = validation.reason ? 
        `[Voice] Correction: ${previousCount} ‚Üí ${newCount} (${validation.reason})` :
        `[Voice] Correction: ${previousCount} ‚Üí ${newCount}`;
    console.log(logMessage);
    
    // Arr√™ter √©coute passive et confirmer
    stopPassiveListening();
    
    // Confirmation imm√©diate
    if (VOICE_FEATURES.validation_ui && voiceState === 'VALIDATING') {
        confirmVoiceCount(newCount);
    }
}

/**
 * Applique la correction de count avec feedback utilisateur
 * 
 * @param {number} newCount - Nouveau count corrig√©
 */
function applyCorrectionCount(newCount) {
    const previousCount = voiceData.count;
    voiceData.count = newCount;
    
    // Mise √† jour interface imm√©diate
    updateCorrectionUI(newCount, previousCount);
    
    // Feedback utilisateur
    if (navigator.vibrate) {
        navigator.vibrate([50, 50, 50]); // Triple vibration pour correction
    }
    
    // Log de correction
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Correction appliqu√©e: ${previousCount} ‚Üí ${newCount}`);
    
    // Arr√™ter √©coute passive et confirmer
    stopPassiveListening();
    
    // Confirmer imm√©diatement apr√®s correction vocale
    if (VOICE_FEATURES.validation_ui && voiceState === 'VALIDATING') {
        confirmVoiceCount(newCount);
    }
}

/**
 * Met √† jour l'interface apr√®s correction
 * 
 * @param {number} newCount - Nouveau count
 * @param {number} previousCount - Ancien count
 */
function updateCorrectionUI(newCount, previousCount) {
    const repsElement = document.getElementById('setReps');
    if (!repsElement) return;
    
    // Si interface de validation active, mettre √† jour
    const voiceCountElement = document.querySelector('.voice-count');
    if (voiceCountElement) {
        voiceCountElement.textContent = newCount;
        
        // Animation de correction
        voiceCountElement.style.background = 'var(--info, #17a2b8)';
        voiceCountElement.style.color = 'white';
        voiceCountElement.style.padding = '0.2rem 0.4rem';
        voiceCountElement.style.borderRadius = '4px';
        voiceCountElement.style.transition = 'all 0.3s ease';
        
        setTimeout(() => {
            voiceCountElement.style.background = '';
            voiceCountElement.style.color = '';
            voiceCountElement.style.padding = '';
            voiceCountElement.style.borderRadius = '';
        }, 1000);
    } else {
        // Interface normale
        repsElement.textContent = newCount;
        repsElement.style.color = 'var(--info, #17a2b8)';
        setTimeout(() => {
            repsElement.style.color = '';
        }, 800);
    }
}

/**
 * Traite la d√©tection d'un mot-cl√© avec logique de monotonie
 */
function handleKeywordDetected() {
    voiceData.count++;
    
    // Mise √† jour UI
    debouncedVoiceDisplay(voiceData.count, voiceData.targetReps || 12, { voiceActive: true });
    
    // Feedback
    if (navigator.vibrate) {
        navigator.vibrate(30);
    }
    
    // Reset timer
    if (typeof resetAutoValidationTimer === 'function') {
        resetAutoValidationTimer();
    }
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Keyword ‚Üí ${voiceData.count}`);
}

/**
 * Met √† jour la pr√©diction pour le prochain nombre
 * 
 * @param {number} nextNumber - Prochain nombre attendu
 */
function updatePrediction(nextNumber) {
    predictedNext = nextNumber;
    
    // Optionnel: indicateur visuel du prochain nombre attendu
    const repsElement = document.getElementById('setReps');
    if (repsElement && predictedNext <= 50) {
        repsElement.setAttribute('data-next', predictedNext);
    }
}

/**
 * Met √† jour l'affichage du compteur de r√©p√©titions
 * Compatible avec ancienne et nouvelle interface
 * 
 * @param {number} count - Nombre de r√©p√©titions d√©tect√©es
 * @returns {void}
 */
function updateVoiceDisplay(count) {
    // Priorit√© √† l'interface moderne
    if (document.getElementById('repsDisplay')) {
        // R√©cup√©rer l'objectif depuis l'interface
        const targetEl = document.getElementById('targetRep');
        const targetReps = targetEl ? parseInt(targetEl.textContent) || 12 : 12;
        
        // Utiliser la fonction moderne
        debouncedVoiceDisplay(count, targetReps, { voiceActive: true });
        
        // Mettre √† jour voiceData
        voiceData.count = count;
        displayedCount = count;
        
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Affichage moderne mis √† jour: ${count}/${targetReps}`);
        return;
    }
    
    // Fallback sur ancienne interface
    const repsElement = document.getElementById('setReps');
    if (!repsElement) {
        console.warn('[Voice] Aucun √©l√©ment d\'affichage trouv√©');
        return;
    }
    
    // Mise √† jour simple pour legacy
    repsElement.textContent = count;
    voiceData.count = count;
    displayedCount = count;
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Affichage legacy mis √† jour: ${count}`);
}

/**
 * Met √† jour l'indicateur micro de fa√ßon optimis√©e
 */
function updateMicroIndicator(count) {
    let indicator = document.querySelector('.voice-indicator');
    
    if (!indicator && count > 0) {
        // Cr√©er seulement si n√©cessaire
        const microIcon = document.querySelector('.voice-toggle-container i');
        if (microIcon) {
            indicator = document.createElement('div');
            indicator.className = 'voice-indicator';
            microIcon.parentElement.appendChild(indicator);
        }
    }
    
    if (indicator) {
        // Mise √† jour directe
        indicator.textContent = count;
        indicator.classList.add('pulse');
        
        setTimeout(() => {
            indicator.classList.remove('pulse');
        }, 300);
    }
}

/**
 * Gestionnaire d'erreurs de la reconnaissance vocale
 * G√®re les erreurs de permissions, r√©seau, etc.
*/
function handleVoiceError(event) {
    // Erreurs ignorables sur Android
    if (PLATFORM_CONFIG.isAndroid) {
        if (event.error === 'no-speech' || event.error === 'aborted') {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Erreur normale, restart automatique');
            return;
        }
    }
    // Gestion sp√©ciale "aborted"
    if (event.error === 'aborted') {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Reconnaissance aborted - transition propre');
        voiceRecognitionActive = false;
        // NE PAS changer l'√©tat visuel pour 'aborted' - √©viter confusion
        return;
    }
    
    // Pour toutes les autres erreurs r√©elles
    voiceRecognitionActive = false;
    updateMicrophoneVisualState('error');
    
    switch(event.error) {
        case 'no-speech':
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Aucune parole d√©tect√©e - normal');
            // Ne PAS afficher d'erreur pour no-speech mais reset l'√©tat
            setTimeout(() => {
                if (voiceRecognitionActive) {
                    updateMicrophoneVisualState('listening');
                }
            }, 1000);
            break;
            
        case 'audio-capture':
            console.error('[Voice] Pas de microphone disponible');
            showToast('Microphone non disponible', 'error');
            voiceRecognitionActive = false;
            break;
            
        case 'not-allowed':
            console.error('[Voice] Permission microphone refus√©e');
            showToast('Permission microphone refus√©e', 'error');
            voiceRecognitionActive = false;
            break;
            
        default:
            console.error('[Voice] Erreur:', event.error);
    }
}

/**
 * Gestionnaire de fin de reconnaissance vocale
 * Red√©marre automatiquement si n√©cessaire
 */
function handleVoiceEnd() {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] ============ handleVoiceEnd START ============');
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] √âtat actuel:', {
        timestamp: new Date().toISOString(),
        voiceActive: voiceRecognitionActive,
        workoutState: window.workoutState?.current,
        isAndroid: PLATFORM_CONFIG?.isAndroid,
        shouldRestart: false // sera calcul√©
    });
    
    // Comportement sp√©cifique Android
    if (PLATFORM_CONFIG?.isAndroid) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Android d√©tect√©, v√©rification restart...');
        
        const shouldRestart = shouldRestartAndroid();
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] shouldRestartAndroid() =', shouldRestart);
        
        if (shouldRestart) {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Conditions OK, appel handleAndroidRestart()');
            handleAndroidRestart();
            return;
        } else {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Conditions restart NON remplies');
        }
    } else {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Pas Android ou PLATFORM_CONFIG manquant');
    }
    
    // Comportement desktop normal
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] Comportement normal (pas de restart)');
    voiceRecognitionActive = false;
    updateMicrophoneVisualState('inactive');
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] ============ handleVoiceEnd END ============');
}

/**
 * V√©rifier si restart Android n√©cessaire
 */
function shouldRestartAndroid() {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] shouldRestartAndroid() check:', {
        voiceRecognitionActive: voiceRecognitionActive,
        workoutState: window.workoutState?.current,
        visibility: document.visibilityState,
        restartCount: androidRestartCount,
        maxRestarts: PLATFORM_CONFIG?.android?.maxRestarts
    });
    
    const result = voiceRecognitionActive && 
           window.workoutState?.current === 'ready' &&
           document.visibilityState === 'visible' &&
           androidRestartCount < (PLATFORM_CONFIG?.android?.maxRestarts || 30);
           
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] shouldRestartAndroid() result:', result);
    return result;
}

/**
 * Gestion du restart Android
 */
function handleAndroidRestart() {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] handleAndroidRestart() APPEL√â', {
        restartCount: androidRestartCount,
        sessionStartTime: androidSessionStartTime,
        currentTime: Date.now()
    });
    
    // V√©rifications de s√©curit√©
    if (androidRestartCount >= PLATFORM_CONFIG.android.maxRestarts) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Limite de restarts atteinte');
        stopVoiceRecognitionWithReason('Limite de red√©marrages atteinte');
        return;
    }
    
    const sessionDuration = Date.now() - androidSessionStartTime;
    if (sessionDuration > PLATFORM_CONFIG.android.sessionTimeout) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Timeout session atteint');
        stopVoiceRecognitionWithReason('Session expir√©e');
        return;
    }
    
    // Pr√©server l'√©tat
    const preservedState = {
        count: voiceData.count || 0,
        timestamps: voiceData.timestamps ? [...voiceData.timestamps] : [],
        gaps: voiceData.gaps ? [...voiceData.gaps] : [],
        lastNumber: voiceData.lastNumber || 0,
        confidence: voiceData.confidence || 1
    };
    
    androidRestartCount++;
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Android] Restart #${androidRestartCount}`);
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] √âtat pr√©serv√©:', preservedState);
    
    // NE PAS toucher √† voiceRecognitionActive ici !
    // Le micro est encore techniquement actif du point de vue de l'API
    
    // Restart imm√©diat sans d√©lai
    try {
        // D'abord restaurer l'√©tat
        Object.assign(voiceData, preservedState);
        window.voiceData = voiceData;
        
        // Puis restart direct
        recognition.stop();
        
        // Petit d√©lai pour laisser l'API respirer
        setTimeout(() => {
            try {
                recognition.start();
                voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Restart r√©ussi, √©tat restaur√©');
                
                // Garder l'interface synchronis√©e
                updateMicrophoneVisualState('listening');
                
            } catch (e) {
                console.error('[Android] Erreur au restart:', e);
                voiceRecognitionActive = false;
                updateMicrophoneVisualState('inactive');
            }
        }, 20);
        
    } catch (error) {
        console.error('[Android] Erreur:', error);
        voiceRecognitionActive = false;
        updateMicrophoneVisualState('inactive');
    }
}

/**
 * Arr√™t avec raison
 */
function stopVoiceRecognitionWithReason(reason) {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Arr√™t:', reason);
    
    if (window.showToast) {
        window.showToast(`Micro arr√™t√© : ${reason}`, 'warning');
    }
    
    cleanupAndroidResources();
    stopVoiceRecognition();
}

/**
 * Cleanup ressources Android
 */
function cleanupAndroidResources() {
    // Cleanup timers
    if (androidRestartTimer) {
        clearTimeout(androidRestartTimer);
        androidRestartTimer = null;
    }
    
    // Reset compteurs
    androidRestartCount = 0;
    androidLastTranscripts = [];
    
    // NOUVEAU : Reset cache et √©tat vocal
    if (recognitionCache) {
        recognitionCache.clear();
    }
    
    // Reset voiceData complet
    voiceData = {
        count: 0,
        timestamps: [],
        gaps: [],
        lastNumber: 0,
        confidence: 1.0
    };
    
    // Reset flags de cache
    cachedConfidence = null;
    confidenceInvalidated = true;
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Cleanup complet effectu√©');
}

/**
 * Gestion visibilit√© page
 */
function handleVisibilityChange() {
    if (document.visibilityState === 'hidden' && PLATFORM_CONFIG.isAndroid) {
        if (androidRestartTimer) {
            clearTimeout(androidRestartTimer);
            androidRestartTimer = null;
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Page cach√©e, restarts suspendus');
        }
    }
}

/**
 * D√©tection de doublons Android
 */
// Version optimis√©e O(1)
let duplicateCache = new Set();

function isAndroidDuplicate(transcript) {
    const now = Date.now();
    const timeWindow = Math.floor(now / 1000); // Fen√™tre 1 seconde
    const cacheKey = `${transcript.toLowerCase().trim()}_${timeWindow}`;
    
    if (duplicateCache.has(cacheKey)) {
        return true;
    }
    
    duplicateCache.add(cacheKey);
    
    // Cleanup toutes les 10 secondes
    if (duplicateCache.size > 20) {
        duplicateCache.clear();
    }
    
    return false;
}


// ===== FONCTIONS UTILITAIRES =====

/**
 * Calcule le tempo moyen entre les r√©p√©titions
 * @param {number[]} timestamps - Tableau des timestamps en millisecondes
 * @returns {number|null} - Tempo moyen en millisecondes ou null si insuffisant
 */
function calculateAvgTempo(timestamps) {
    if (!timestamps || timestamps.length < 2) {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Pas assez de timestamps pour calculer le tempo');
        return null;
    }
    
    const intervals = [];
    for (let i = 1; i < timestamps.length; i++) {
        const interval = timestamps[i] - timestamps[i-1];
        intervals.push(interval);
    }
    
    const avgTempo = Math.round(
        intervals.reduce((sum, interval) => sum + interval, 0) / intervals.length
    );
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Tempo moyen calcul√©:', avgTempo, 'ms entre reps');
    return avgTempo;
}

/**
 * Valide les donn√©es vocales avant envoi
 * V√©rifie coh√©rence et qualit√© des donn√©es
 * 
 * @param {Object} data - Donn√©es vocales √† valider
 * @returns {boolean} true si donn√©es valides
 */
function validateVoiceData(data) {
    // TODO: V√©rifier structure obligatoire
    // TODO: Valider coh√©rence count/timestamps
    // TODO: V√©rifier plausibilit√© des gaps
    // TODO: Calculer score de confiance
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation donn√©es (placeholder):', data);
    return false;
}

/**
 * Collecte l'√©tat de sant√© du syst√®me vocal pour monitoring
 */
function getVoiceSystemHealth() {
    return {
        // √âtat syst√®me
        speechRecognitionSupported: !!window.SpeechRecognition || !!window.webkitSpeechRecognition,
        voiceRecognitionActive: voiceRecognitionActive,
        userVoiceEnabled: currentUser?.voice_counting_enabled || false,
        workoutState: workoutState.current,
        
        // √âtat DOM
        voiceContainer: !!document.getElementById('voiceStatusContainer'),
        voiceIcon: !!document.querySelector('#voiceStatusIcon'),
        
        // √âtat donn√©es
        currentMicState: currentMicState,
        voiceDataCount: voiceData?.count || 0,
        
        // Permissions
        microphonePermission: 'unknown' // sera mis √† jour par checkMicrophonePermissions
    };
}


/**
 * Valide la coh√©rence du syst√®me vocal
 */
function validateVoiceSystemCoherence() {
    const health = getVoiceSystemHealth();
    const issues = [];
    
    // V√©rifications coh√©rence
    if (health.recognitionActive && health.currentState === 'LISTENING' && health.timersActive === 0) {
        issues.push('Recognition active mais aucun timer');
    }
    
    if (health.memoryUsage > 100) {
        issues.push('Cache recognition surcharg√©');
    }
    
    if (issues.length > 0) {
        console.warn('[Voice] Issues d√©tect√©es:', issues);
    }
    
    return { healthy: issues.length === 0, issues };
}


// ===== DEBUG ANDROID =====
window.getAndroidVoiceStats = function() {
    if (!PLATFORM_CONFIG.isAndroid) {
        return { platform: 'desktop', message: 'Pas de stats Android' };
    }
    
    const sessionDuration = Date.now() - androidSessionStartTime;
    
    return {
        platform: 'Android',
        restartCount: androidRestartCount,
        maxRestarts: PLATFORM_CONFIG.android.maxRestarts,
        sessionDuration: Math.round(sessionDuration / 1000) + 's',
        duplicatesInCache: androidLastTranscripts.length,
        currentState: voiceRecognitionActive ? 'active' : 'inactive',
        workoutState: window.workoutState?.current,
        voiceData: {
            count: voiceData?.count || 0,
            gaps: voiceData?.gaps || [],
            confidence: voiceData?.confidence || 0
        }
    };
};


window.checkAndroidState = function() {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID DEBUG] √âtat complet:', {
        platformConfig: PLATFORM_CONFIG,
        androidRestartCount: typeof androidRestartCount !== 'undefined' ? androidRestartCount : 'UNDEFINED',
        androidSessionStartTime: typeof androidSessionStartTime !== 'undefined' ? androidSessionStartTime : 'UNDEFINED',
        androidRestartTimer: typeof androidRestartTimer !== 'undefined' ? androidRestartTimer : 'UNDEFINED',
        androidLastTranscripts: typeof androidLastTranscripts !== 'undefined' ? androidLastTranscripts : 'UNDEFINED',
        functionsExist: {
            shouldRestartAndroid: typeof shouldRestartAndroid === 'function',
            handleAndroidRestart: typeof handleAndroidRestart === 'function',
            cleanupAndroidResources: typeof cleanupAndroidResources === 'function'
        }
    });
};





window.resetAndroidVoice = function() {
    cleanupAndroidResources();
    androidSessionStartTime = Date.now();
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Android] Reset forc√© effectu√©');
};










// ===== PATCH ANDROID SIMPLIFI√â =====
voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] Chargement...');

if (PLATFORM_CONFIG?.isAndroid) {
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] Android d√©tect√©:', true);
    
    // Sauvegarder l'ancienne fonction
    const originalHandleVoiceEnd = window.handleVoiceEnd;
    
    // Remplacer par une version qui NE fait PAS le comportement normal
    window.handleVoiceEnd = function() {
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] handleVoiceEnd intercept√©');
        
        // Si on doit red√©marrer, NE PAS appeler l'original
        if (shouldRestartAndroid()) {
            voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] Restart Android d√©tect√© - bypass comportement normal');
            handleAndroidRestart();
            // RETURN ICI - ne pas ex√©cuter le reste
            return;
        }
        
        // Sinon, comportement normal
        voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] Pas de restart - comportement normal');
        if (typeof originalHandleVoiceEnd === 'function') {
            originalHandleVoiceEnd();
        }
    };
    
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] handleVoiceEnd remplac√© avec logique restart');
    window.testAndroidPatch = () => voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[ANDROID PATCH] Test OK');
}















// Exposition pour debug
window.getVoiceSystemHealth = getVoiceSystemHealth;
window.validateVoiceSystemCoherence = validateVoiceSystemCoherence;

// ===== EXPORTS GLOBAUX =====

// Exposer les fonctions principales dans l'objet window
// pour utilisation depuis app.js et autres modules
window.voiceData = voiceData;
window.initVoiceRecognition = initVoiceRecognition;
window.startVoiceRecognition = startVoiceRecognition;
window.stopVoiceRecognition = stopVoiceRecognition;
window.showValidationModal = showValidationModal;
window.adjustVoiceCount = adjustVoiceCount;
window.confirmVoiceCount = confirmVoiceCount;
window.clearValidationUI = clearValidationUI;
window.toggleValidationUI = () => {
    VOICE_FEATURES.validation_ui = !VOICE_FEATURES.validation_ui;
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Validation UI:', VOICE_FEATURES.validation_ui ? 'ACTIV√âE' : 'D√âSACTIV√âE');
};

// Exposer variables globales pour debug et monitoring
window.voiceRecognitionActive = () => voiceRecognitionActive;
window.getVoiceData = () => voiceData;
window.calculateAvgTempo = calculateAvgTempo;
// NOUVEAU - Exposer les fonctions de correction vocale
window.handleCorrection = handleCorrection;
window.startPassiveListening = startPassiveListening;
window.stopPassiveListening = stopPassiveListening;
window.applyCorrectionCount = applyCorrectionCount;

// Debug helpers pour correction
window.testCorrection = (count = 15) => {
    applyCorrectionCount(count);
};

window.toggleCorrectionMode = () => {
    if (passiveListening) {
        stopPassiveListening();
    } else {
        startPassiveListening();
    }
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Mode correction:', passiveListening ? 'ACTIF' : 'INACTIF');
};
// NOUVEAU - Exposer les fonctions d'auto-validation
window.scheduleAutoValidation = scheduleAutoValidation;
window.confirmFinalCount = confirmFinalCount;
window.cancelVoiceValidation = cancelVoiceValidation;
window.resetVoiceState = resetVoiceState;

// NOUVEAU - Exposer m√©triques pour debug
window.voiceMetrics = voiceMetrics;
window.getVoiceStats = () => voiceMetrics.getStats();
window.resetVoiceStats = () => voiceMetrics.reset();

// Debug helpers pour auto-validation
window.testAutoValidation = (count = 15, confidence = 0.9) => {
    voiceData.count = count;
    voiceData.confidence = confidence;
    voiceData.startTime = Date.now();
    scheduleAutoValidation();
};

window.forceExecuteSet = () => {
    if (typeof window.executeSet === 'function') {
        window.executeSet();
    }
};

// ===== EXPOSITIONS MANQUANTES √âTAPE 4 =====

// Exposer les constantes
window.VOICE_FEATURES = VOICE_FEATURES;
window.CONFIDENCE_LEVELS = CONFIDENCE_LEVELS;
window.DEBUG_MODE = DEBUG_MODE;

// Exposer les variables d'√©tat
window.voiceState = () => voiceState;
window.validationTimer = () => validationTimer;

// S'assurer que les m√©triques sont expos√©es
window.voiceMetrics = voiceMetrics;

// V√©rifier que les fonctions auto-validation sont expos√©es
if (typeof scheduleAutoValidation !== 'undefined') {
    window.scheduleAutoValidation = scheduleAutoValidation;
} else {
    console.warn('[Voice] scheduleAutoValidation non d√©finie');
}

if (typeof scheduleQuickValidation !== 'undefined') {
    window.scheduleQuickValidation = scheduleQuickValidation;
} else {
    console.warn('[Voice] scheduleQuickValidation non d√©finie');
}

if (typeof scheduleStandardValidation !== 'undefined') {
    window.scheduleStandardValidation = scheduleStandardValidation;
} else {
    console.warn('[Voice] scheduleStandardValidation non d√©finie');
}
// === EXPOSITION FONCTIONS PHASE 1 ===
window.updateMicrophoneVisualState = updateMicrophoneVisualState;

voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] ‚úÖ Toutes les expositions globales configur√©es');

// Initialiser l'√©tat micro au chargement des s√©ances
document.addEventListener('DOMContentLoaded', () => {
    // CRITIQUE : Initialiser l'instance imm√©diatement
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Initialisation automatique au chargement...');
    const initSuccess = initVoiceRecognition();
    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, `[Voice] Init au d√©marrage: ${initSuccess ? 'SUCCESS' : 'FAILED'}`);
    
    setTimeout(() => {
        const container = document.getElementById('voiceStatusContainer');
        if (container) {
            checkMicrophonePermissions().then(hasPermission => {
                if (hasPermission) {
                    updateMicrophoneVisualState('inactive'); // √âtat par d√©faut
                    voiceLog(VOICE_DEBUG_LEVEL.NORMAL, '[Voice] Permissions accord√©es, √©tat initial configur√©');
                } else {
                    updateMicrophoneVisualState('error');
                }
            });
        }
    }, 600);
});